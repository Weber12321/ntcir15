{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "# from sklearn import cross_validation\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "dataset = pd.read_excel(r'./200416_label0_dataset_sentence.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>round</th>\n",
       "      <th>sender</th>\n",
       "      <th>texts</th>\n",
       "      <th>max_label</th>\n",
       "      <th>round_label</th>\n",
       "      <th>labels</th>\n",
       "      <th>sender_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>1</td>\n",
       "      <td>customer</td>\n",
       "      <td>内涵 段子 联通 皮 点赞 中国联通 中国联通 客服 掌上 营业厅 内涵 段子 话题 封 郑...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>2</td>\n",
       "      <td>helpdesk</td>\n",
       "      <td>u</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>3</td>\n",
       "      <td>customer</td>\n",
       "      <td>夸夸</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>4</td>\n",
       "      <td>helpdesk</td>\n",
       "      <td>*</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4121001149457180</td>\n",
       "      <td>1</td>\n",
       "      <td>customer</td>\n",
       "      <td>距离 反映 问题 已经 一个 星期 花粉 助手 D 荣耀 honor 荣耀 手机 华为 终端...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  round    sender  \\\n",
       "0  4227729258237820      1  customer   \n",
       "1  4227729258237820      2  helpdesk   \n",
       "2  4227729258237820      3  customer   \n",
       "3  4227729258237820      4  helpdesk   \n",
       "4  4121001149457180      1  customer   \n",
       "\n",
       "                                               texts  max_label  round_label  \\\n",
       "0  内涵 段子 联通 皮 点赞 中国联通 中国联通 客服 掌上 营业厅 内涵 段子 话题 封 郑...          3            2   \n",
       "1                                                  u          6            4   \n",
       "2                                                 夸夸          3            0   \n",
       "3                                                  *          6            4   \n",
       "4  距离 反映 问题 已经 一个 星期 花粉 助手 D 荣耀 honor 荣耀 手机 华为 终端...          2            2   \n",
       "\n",
       "   labels  sender_num  \n",
       "0       1           0  \n",
       "1       0           1  \n",
       "2       1           0  \n",
       "3       0           1  \n",
       "4       1           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = []\n",
    "for i in dataset['sender']:\n",
    "    if i == 'customer':\n",
    "        tmp.append(0)\n",
    "    else:\n",
    "        tmp.append(1)\n",
    "dataset['sender_num'] = tmp\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(dataset[\"texts\"])\n",
    "labels = list(dataset[\"labels\"])\n",
    "Round = list(dataset[\"round\"])\n",
    "sender_num = list(dataset[\"sender_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train=texts[1755:]\n",
    "# x_test=texts[0:1755]\n",
    "# y_train=labels[1755:]\n",
    "# y_test=labels[0:1755]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "def baseline_model(texts,labels):\n",
    "    \n",
    "    x_train = tfidf_vectorizer.fit_transform(texts).toarray()\n",
    "#     x_test = tfidf_vectorizer.transform(x_test)\n",
    "    svd = TruncatedSVD(n_components=10).fit(x_train)\n",
    "    reduced = svd.transform(x_train)\n",
    "    total = reduced.tolist()\n",
    "    for item in range(len(total)):\n",
    "        total[item] = np.append(total[item], sender_num[item])\n",
    "    for item in range(len(total)):\n",
    "        total[item] = np.append(total[item], Round[item])\n",
    "    \n",
    "    Models = ['Bernoulli NB','Svm (linear)','Logistic Regression',\n",
    "              'Random Forest','kNN','Decision Tree']\n",
    "    function = [BernoulliNB(),svm.SVC(kernel=\"linear\"),LogisticRegression(),\n",
    "              RandomForestClassifier(),KNeighborsClassifier(),DecisionTreeClassifier()]\n",
    "    perform_f1 = []\n",
    "    perform_acc = []\n",
    "    perform_recall = []\n",
    "    perform_precision = []\n",
    "    \n",
    "    for i in tqdm(range(len(function))):\n",
    "        model = function[i]\n",
    "        performance = cross_val_score(model, total, labels, cv=10, scoring='accuracy')\n",
    "        performance1 = cross_val_score(model, total, labels, cv=10, scoring='f1_weighted')\n",
    "        performance2 = cross_val_score(model, total, labels, cv=10, scoring='recall')\n",
    "        performance3 = cross_val_score(model, total, labels, cv=10, scoring='precision')\n",
    "        \n",
    "        func = str(function[i])\n",
    "        print(\"==== \", func[0:func.index('(')], \" ====\")\n",
    "        perform_acc.append(performance.mean())\n",
    "        perform_f1.append(performance1.mean())\n",
    "        perform_recall.append(performance2.mean())\n",
    "        perform_precision.append(performance3.mean())\n",
    "\n",
    "#         model.fit(x_train, y_train)\n",
    "#         model.score(x_test, y_test)\n",
    "#         e = y_test\n",
    "#         p = model.predict(x_test)\n",
    "#         print(metrics.classification_report(e,p))\n",
    "#         perform_f1.append(metrics.f1_score(e,p,average='macro'))\n",
    "#         perform_acc.append(metrics.accuracy_score(e,p))\n",
    "        \n",
    "    result_f1_table = pd.DataFrame({\"Models\":Models,\"f1-scores\":perform_f1,\"accuracy\":perform_acc\n",
    "                                   ,\"recall\":perform_recall,\"precision\":perform_precision})\n",
    "#     result_acc_table = pd.DataFrame({\"Models\":Models,\"Result acc scores\":perform_acc})\n",
    "    return result_f1_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c053cc687e684a35a8894ec585ef286e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====  BernoulliNB  ====\n",
      "====  SVC  ====\n",
      "====  LogisticRegression  ====\n",
      "====  RandomForestClassifier  ====\n",
      "====  KNeighborsClassifier  ====\n",
      "====  DecisionTreeClassifier  ====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "score1 = baseline_model(texts,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>f1-scores</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bernoulli NB</td>\n",
       "      <td>0.802508</td>\n",
       "      <td>0.799593</td>\n",
       "      <td>0.920613</td>\n",
       "      <td>0.671578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Svm (linear)</td>\n",
       "      <td>0.934208</td>\n",
       "      <td>0.935644</td>\n",
       "      <td>0.829955</td>\n",
       "      <td>0.999817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.934208</td>\n",
       "      <td>0.935644</td>\n",
       "      <td>0.829955</td>\n",
       "      <td>0.999817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.931852</td>\n",
       "      <td>0.931972</td>\n",
       "      <td>0.840747</td>\n",
       "      <td>0.976717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.922059</td>\n",
       "      <td>0.922879</td>\n",
       "      <td>0.852771</td>\n",
       "      <td>0.937787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.905876</td>\n",
       "      <td>0.904983</td>\n",
       "      <td>0.881756</td>\n",
       "      <td>0.868630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Models  f1-scores  accuracy    recall  precision\n",
       "0         Bernoulli NB   0.802508  0.799593  0.920613   0.671578\n",
       "1         Svm (linear)   0.934208  0.935644  0.829955   0.999817\n",
       "2  Logistic Regression   0.934208  0.935644  0.829955   0.999817\n",
       "3        Random Forest   0.931852  0.931972  0.840747   0.976717\n",
       "4                  kNN   0.922059  0.922879  0.852771   0.937787\n",
       "5        Decision Tree   0.905876  0.904983  0.881756   0.868630"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def baseline_model(x_train, x_test, y_train, y_test):\n",
    "    \n",
    "#     x_train = tfidf_vectorizer.fit_transform(x_train)\n",
    "#     x_test = tfidf_vectorizer.transform(x_test)\n",
    "    \n",
    "#     Models = ['Bernoulli NB','Multinomial NB','Svm (linear)','Logistic Regression',\n",
    "#               'Random Forest','kNN','Decision Tree']\n",
    "#     function = [BernoulliNB(),MultinomialNB(),svm.SVC(kernel=\"linear\"),LogisticRegression(),\n",
    "#               RandomForestClassifier(),KNeighborsClassifier(),DecisionTreeClassifier()]\n",
    "#     perform_f1 = []\n",
    "#     perform_acc = []\n",
    "    \n",
    "    \n",
    "#     for i in tqdm(range(len(function))):\n",
    "#         model = function[i]\n",
    "# #         performance = cross_val_score(model, tfidf_vectorizer.fit_transform(texts), labels, cv=10, scoring'accuracy')\n",
    "        \n",
    "#         func = str(function[i])\n",
    "#         print(\"==== \", func[0:func.index('(')], \" ====\")\n",
    "\n",
    "#         model.fit(x_train, y_train)\n",
    "#         model.score(x_test, y_test)\n",
    "#         e = y_test\n",
    "#         p = model.predict(x_test)\n",
    "#         print(metrics.classification_report(e,p))\n",
    "#         perform_f1.append(metrics.f1_score(e,p,average='macro'))\n",
    "#         perform_acc.append(metrics.accuracy_score(e,p))\n",
    "        \n",
    "#     result_f1_table = pd.DataFrame({\"Models\":Models,\"Result f1 scores\":perform_f1})\n",
    "#     result_acc_table = pd.DataFrame({\"Models\":Models,\"Result acc scores\":perform_acc})\n",
    "#     return result_f1_table, result_acc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed578962b314bc89482db9c45a1f0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====  BernoulliNB  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      1624\n",
      "           1       0.25      0.01      0.01       131\n",
      "\n",
      "    accuracy                           0.92      1755\n",
      "   macro avg       0.59      0.50      0.49      1755\n",
      "weighted avg       0.88      0.92      0.89      1755\n",
      "\n",
      "====  MultinomialNB  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      1624\n",
      "           1       0.00      0.00      0.00       131\n",
      "\n",
      "    accuracy                           0.93      1755\n",
      "   macro avg       0.46      0.50      0.48      1755\n",
      "weighted avg       0.86      0.93      0.89      1755\n",
      "\n",
      "====  SVC  ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1624\n",
      "           1       0.84      0.31      0.46       131\n",
      "\n",
      "    accuracy                           0.94      1755\n",
      "   macro avg       0.89      0.65      0.71      1755\n",
      "weighted avg       0.94      0.94      0.93      1755\n",
      "\n",
      "====  LogisticRegression  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1624\n",
      "           1       0.81      0.26      0.39       131\n",
      "\n",
      "    accuracy                           0.94      1755\n",
      "   macro avg       0.88      0.63      0.68      1755\n",
      "weighted avg       0.93      0.94      0.93      1755\n",
      "\n",
      "====  RandomForestClassifier  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      1624\n",
      "           1       0.70      0.24      0.36       131\n",
      "\n",
      "    accuracy                           0.94      1755\n",
      "   macro avg       0.82      0.62      0.66      1755\n",
      "weighted avg       0.92      0.94      0.92      1755\n",
      "\n",
      "====  KNeighborsClassifier  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      1624\n",
      "           1       0.28      0.25      0.27       131\n",
      "\n",
      "    accuracy                           0.90      1755\n",
      "   macro avg       0.61      0.60      0.61      1755\n",
      "weighted avg       0.89      0.90      0.89      1755\n",
      "\n",
      "====  DecisionTreeClassifier  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      1624\n",
      "           1       0.40      0.40      0.40       131\n",
      "\n",
      "    accuracy                           0.91      1755\n",
      "   macro avg       0.68      0.67      0.68      1755\n",
      "weighted avg       0.91      0.91      0.91      1755\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# score = baseline_model(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer1=p.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dict1 = {\"label\": answer1,  \n",
    "       }\n",
    "select_df = pd.DataFrame(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_df.to_csv('answer1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
