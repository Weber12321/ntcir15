{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "# from sklearn import cross_validation\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "dataset = pd.read_excel(r'./200416_label0_dataset_sentence.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>round</th>\n",
       "      <th>sender</th>\n",
       "      <th>texts</th>\n",
       "      <th>max_label</th>\n",
       "      <th>round_label</th>\n",
       "      <th>labels</th>\n",
       "      <th>sender_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>1</td>\n",
       "      <td>customer</td>\n",
       "      <td>内涵 段子 联通 皮 点赞 中国联通 中国联通 客服 掌上 营业厅 内涵 段子 话题 封 郑...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>2</td>\n",
       "      <td>helpdesk</td>\n",
       "      <td>u</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>3</td>\n",
       "      <td>customer</td>\n",
       "      <td>夸夸</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>4</td>\n",
       "      <td>helpdesk</td>\n",
       "      <td>*</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4121001149457180</td>\n",
       "      <td>1</td>\n",
       "      <td>customer</td>\n",
       "      <td>距离 反映 问题 已经 一个 星期 花粉 助手 D 荣耀 honor 荣耀 手机 华为 终端...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  round    sender  \\\n",
       "0  4227729258237820      1  customer   \n",
       "1  4227729258237820      2  helpdesk   \n",
       "2  4227729258237820      3  customer   \n",
       "3  4227729258237820      4  helpdesk   \n",
       "4  4121001149457180      1  customer   \n",
       "\n",
       "                                               texts  max_label  round_label  \\\n",
       "0  内涵 段子 联通 皮 点赞 中国联通 中国联通 客服 掌上 营业厅 内涵 段子 话题 封 郑...          3            2   \n",
       "1                                                  u          6            4   \n",
       "2                                                 夸夸          3            0   \n",
       "3                                                  *          6            4   \n",
       "4  距离 反映 问题 已经 一个 星期 花粉 助手 D 荣耀 honor 荣耀 手机 华为 终端...          2            2   \n",
       "\n",
       "   labels  sender_num  \n",
       "0       1           0  \n",
       "1       0           1  \n",
       "2       1           0  \n",
       "3       0           1  \n",
       "4       1           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = []\n",
    "for i in dataset['sender']:\n",
    "    if i == 'customer':\n",
    "        tmp.append(0)\n",
    "    else:\n",
    "        tmp.append(1)\n",
    "dataset['sender_num'] = tmp\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(dataset[\"texts\"])\n",
    "# labels = list(dataset[\"labels\"])\n",
    "max_label = list(dataset[\"max_label\"])\n",
    "Round = list(dataset[\"round\"])\n",
    "sender_num = list(dataset[\"sender_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=texts[1755:]\n",
    "x_test=texts[0:1755]\n",
    "y_train=max_label[1755:]\n",
    "y_test=max_label[0:1755]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    x_train = tfidf_vectorizer.fit_transform(x_train)\n",
    "    x_test = tfidf_vectorizer.transform(x_test)\n",
    "    \n",
    "    Models = ['Bernoulli NB','Multinomial NB','Svm (linear)','Logistic Regression',\n",
    "              'Random Forest','kNN','Decision Tree']\n",
    "    function = [BernoulliNB(),MultinomialNB(),svm.SVC(kernel=\"linear\"),LogisticRegression(),\n",
    "              RandomForestClassifier(),KNeighborsClassifier(),DecisionTreeClassifier()]\n",
    "    perform_f1 = []\n",
    "    perform_acc = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(len(function))):\n",
    "        model = function[i]\n",
    "#         performance = cross_val_score(model, tfidf_vectorizer.fit_transform(texts), labels, cv=10, scoring'accuracy')\n",
    "        \n",
    "        func = str(function[i])\n",
    "        print(\"==== \", func[0:func.index('(')], \" ====\")\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        model.score(x_test, y_test)\n",
    "        e = y_test\n",
    "        p = model.predict(x_test)\n",
    "        print(metrics.classification_report(e,p))\n",
    "        perform_f1.append(metrics.f1_score(e,p,average='macro'))\n",
    "        perform_acc.append(metrics.accuracy_score(e,p))\n",
    "        \n",
    "    result_f1_table = pd.DataFrame({\"Models\":Models,\"Result f1 scores\":perform_f1})\n",
    "    result_acc_table = pd.DataFrame({\"Models\":Models,\"Result acc scores\":perform_acc})\n",
    "    return result_f1_table, result_acc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e246cc8fdd0444748360efc6840b19a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====  BernoulliNB  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.88      0.74       477\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       0.88      0.88      0.88       374\n",
      "           3       1.00      0.01      0.02       101\n",
      "           4       0.84      0.90      0.87       662\n",
      "           5       0.00      0.00      0.00        33\n",
      "           6       1.00      0.01      0.02        85\n",
      "\n",
      "    accuracy                           0.77      1755\n",
      "   macro avg       0.62      0.38      0.36      1755\n",
      "weighted avg       0.78      0.77      0.72      1755\n",
      "\n",
      "====  MultinomialNB  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.38      0.50       477\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       0.71      0.94      0.81       374\n",
      "           3       0.00      0.00      0.00       101\n",
      "           4       0.64      0.98      0.78       662\n",
      "           5       0.00      0.00      0.00        33\n",
      "           6       1.00      0.11      0.19        85\n",
      "\n",
      "    accuracy                           0.68      1755\n",
      "   macro avg       0.44      0.34      0.33      1755\n",
      "weighted avg       0.64      0.68      0.61      1755\n",
      "\n",
      "====  SVC  ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77       477\n",
      "           1       0.67      0.17      0.28        23\n",
      "           2       0.87      0.96      0.91       374\n",
      "           3       0.25      0.03      0.05       101\n",
      "           4       0.87      0.91      0.89       662\n",
      "           5       0.00      0.00      0.00        33\n",
      "           6       0.74      0.24      0.36        85\n",
      "\n",
      "    accuracy                           0.80      1755\n",
      "   macro avg       0.58      0.45      0.47      1755\n",
      "weighted avg       0.76      0.80      0.76      1755\n",
      "\n",
      "====  LogisticRegression  ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.88      0.77       477\n",
      "           1       0.75      0.13      0.22        23\n",
      "           2       0.87      0.95      0.91       374\n",
      "           3       0.22      0.02      0.04       101\n",
      "           4       0.87      0.91      0.89       662\n",
      "           5       0.33      0.03      0.06        33\n",
      "           6       0.86      0.22      0.36        85\n",
      "\n",
      "    accuracy                           0.80      1755\n",
      "   macro avg       0.66      0.45      0.46      1755\n",
      "weighted avg       0.77      0.80      0.76      1755\n",
      "\n",
      "====  RandomForestClassifier  ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.73       477\n",
      "           1       0.40      0.17      0.24        23\n",
      "           2       0.89      0.98      0.93       374\n",
      "           3       0.36      0.05      0.09       101\n",
      "           4       0.84      0.91      0.88       662\n",
      "           5       0.00      0.00      0.00        33\n",
      "           6       0.33      0.45      0.38        85\n",
      "\n",
      "    accuracy                           0.78      1755\n",
      "   macro avg       0.51      0.47      0.46      1755\n",
      "weighted avg       0.75      0.78      0.76      1755\n",
      "\n",
      "====  KNeighborsClassifier  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.51      0.43       477\n",
      "           1       0.21      0.13      0.16        23\n",
      "           2       0.83      0.05      0.10       374\n",
      "           3       0.05      0.15      0.07       101\n",
      "           4       0.84      0.41      0.55       662\n",
      "           5       0.33      0.03      0.06        33\n",
      "           6       0.10      0.52      0.17        85\n",
      "\n",
      "    accuracy                           0.34      1755\n",
      "   macro avg       0.39      0.26      0.22      1755\n",
      "weighted avg       0.61      0.34      0.36      1755\n",
      "\n",
      "====  DecisionTreeClassifier  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64       477\n",
      "           1       0.29      0.22      0.25        23\n",
      "           2       0.89      0.90      0.90       374\n",
      "           3       0.19      0.06      0.09       101\n",
      "           4       0.81      0.83      0.82       662\n",
      "           5       0.23      0.21      0.22        33\n",
      "           6       0.24      0.47      0.32        85\n",
      "\n",
      "    accuracy                           0.71      1755\n",
      "   macro avg       0.47      0.47      0.46      1755\n",
      "weighted avg       0.70      0.71      0.70      1755\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = baseline_model(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer1=p.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dict1 = {\"label\": answer1,  \n",
    "       }\n",
    "select_df = pd.DataFrame(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_df.to_csv('answer1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
