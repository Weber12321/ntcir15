{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DialEval-1 DNN practice (with evaluation function)\n",
    "### Model : CNN, LSTM\n",
    "##### input round, sender pred label\n",
    "##### Edited by Weber Huang in 2020-05-28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Eval function and customizes loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "\n",
    "def normalize(pred, truth):\n",
    "    \"\"\" convert inputs to np.array and make sure\n",
    "    inputs are normalized probability distributions\n",
    "    \"\"\"\n",
    "    if len(pred) != len(truth):\n",
    "        raise ValueError(\"pred and truth have different lengths\")\n",
    "    if len(pred) == 0 or len(truth) == 0:\n",
    "        raise ValueError(\"pred or truth are empty\")\n",
    "\n",
    "    pred, truth = np.asarray(pred), np.asarray(truth)\n",
    "    if not ((pred >= 0).all() and (truth >= 0).all()):\n",
    "        raise ValueError(\"probability distribution should not be negative\")\n",
    "    pred, truth = pred / pred.sum(), truth / truth.sum()\n",
    "    return pred, truth\n",
    "\n",
    "def jensen_shannon_div(pred, truth, base=2):\n",
    "    ''' JSD: Jensen-Shannon Divergence\n",
    "    '''\n",
    "    pred, truth = normalize(pred, truth)\n",
    "    m = 1. / 2 * (pred + truth)\n",
    "    return (stats.entropy(pred, m, base=base)\n",
    "            + stats.entropy(truth, m, base=base)) / 2.\n",
    "\n",
    "def root_normalized_squared_error(pred, truth):\n",
    "    \"\"\" RNSS: Root Normalised Sum of Squares\n",
    "    \"\"\"\n",
    "\n",
    "    def squared_error(pred, truth):\n",
    "        return ((pred - truth) ** 2).sum()\n",
    "\n",
    "    pred, truth = normalize(pred, truth)\n",
    "    return np.sqrt(squared_error(pred, truth) / 2)\n",
    "\n",
    "def jsd_custom_loss(y_true, y_pred):\n",
    "            \n",
    "    # calculate loss, using y_pred\n",
    "    ''' JSD: Jensen-Shannon Divergence\n",
    "    '''\n",
    "#     y_pred, y_true = normalize(y_pred, y_true)\n",
    "    m = 1. / 2 * (y_pred + y_true)\n",
    "    # loss = (stats.entropy(y_pred, m, base=2) + stats.entropy(y_true, m, base=2)) / 2.\n",
    "    # tf.keras.losses.KLD()\n",
    "    loss = (tf.keras.losses.KLD(y_pred, m) + tf.keras.losses.KLD(y_true, m)) / 2.\n",
    "    return loss\n",
    "  \n",
    "# model.compile(loss=jsd_custom_loss, optimizer='adam')\n",
    "\n",
    "def rnss_custom_loss(y_true, y_pred):\n",
    "            \n",
    "    # calculate loss, using y_pred\n",
    "    \"\"\" RNSS: Root Normalised Sum of Squares\n",
    "    \"\"\"\n",
    "\n",
    "    def squared_error(y_pred, y_true):\n",
    "        return ((y_pred - y_true) ** 2).sum()\n",
    "\n",
    "#     y_pred, y_true = normalize(y_pred, y_true)\n",
    "    loss = np.sqrt(squared_error(y_pred, y_true) / 2)\n",
    "    \n",
    "    return loss\n",
    "  \n",
    "# model.compile(loss=custom_loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. input dataset and modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('C:/Users/doudi/OneDrive/Documents/ntcir15/Dataset/DialEval-1')\n",
    "df = pd.read_excel(r'./200514_dev+train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>round</th>\n",
       "      <th>sender</th>\n",
       "      <th>texts</th>\n",
       "      <th>max_label</th>\n",
       "      <th>round_label</th>\n",
       "      <th>CNUG</th>\n",
       "      <th>CNUG*</th>\n",
       "      <th>CNUG0</th>\n",
       "      <th>CNaN</th>\n",
       "      <th>HNUG</th>\n",
       "      <th>HNUG*</th>\n",
       "      <th>HNaN</th>\n",
       "      <th>sender_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>1</td>\n",
       "      <td>customer</td>\n",
       "      <td>内涵 段子 联通 皮 点赞 中国联通 中国联通 客服 掌上 营业厅 内涵 段子 话题 封 郑...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>2</td>\n",
       "      <td>helpdesk</td>\n",
       "      <td>u</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>3</td>\n",
       "      <td>customer</td>\n",
       "      <td>夸夸</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>4</td>\n",
       "      <td>helpdesk</td>\n",
       "      <td>*</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4121001149457180</td>\n",
       "      <td>1</td>\n",
       "      <td>customer</td>\n",
       "      <td>距离 反映 问题 已经 一个 星期 花粉 助手 D 荣耀 honor 荣耀 手机 华为 终端...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4121001149457180</td>\n",
       "      <td>2</td>\n",
       "      <td>helpdesk</td>\n",
       "      <td>您好 建议您 先 确认 手机 系统 版本 是否 最新 提示 升级 建议 备份 升 最新 版本...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4121001149457180</td>\n",
       "      <td>3</td>\n",
       "      <td>customer</td>\n",
       "      <td>遗憾 告诉您 网店 表示 解决不了 皮球 踢</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4121001149457180</td>\n",
       "      <td>4</td>\n",
       "      <td>helpdesk</td>\n",
       "      <td>亲 去过 售后</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4121001149457180</td>\n",
       "      <td>5</td>\n",
       "      <td>customer</td>\n",
       "      <td>*</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4121001149457180</td>\n",
       "      <td>6</td>\n",
       "      <td>helpdesk</td>\n",
       "      <td>您好 心情 D 非常 理解 请 放心 D 会 尽我所能 帮 解决问题 烦请 私信 留下 联系...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4121001149457180</td>\n",
       "      <td>7</td>\n",
       "      <td>customer</td>\n",
       "      <td>已经</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4220041064492650</td>\n",
       "      <td>1</td>\n",
       "      <td>customer</td>\n",
       "      <td>锤子 科技 客服 昨晚 优酷 电影 声音 会 自动 变 划 最大值 拉 拉 不住 转换 静音...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4220041064492650</td>\n",
       "      <td>2</td>\n",
       "      <td>helpdesk</td>\n",
       "      <td>抱歉 使用 带来 不便 佩戴 耳机 时 出现 情况 可能 线控 异常 所致 进入 设置 全局...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4220041064492650</td>\n",
       "      <td>3</td>\n",
       "      <td>customer</td>\n",
       "      <td>木有 带 耳机</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4220041064492650</td>\n",
       "      <td>4</td>\n",
       "      <td>helpdesk</td>\n",
       "      <td>未 佩戴 耳机 出现 情况 请 重启 手机 是否 有所改善 无效 重要 数据 保存 电脑 中...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4220041064492650</td>\n",
       "      <td>5</td>\n",
       "      <td>customer</td>\n",
       "      <td>当时 恐怖片 太 吓人</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4024994788689450</td>\n",
       "      <td>1</td>\n",
       "      <td>customer</td>\n",
       "      <td>您好 请问 华为 7i 升级 完 以后 开 不了 机是 情况 震动 一下 华为 页面 黑屏 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4024994788689450</td>\n",
       "      <td>2</td>\n",
       "      <td>helpdesk</td>\n",
       "      <td>您好 手机 反复 重启 进入 不了 界面 请 开机 显示 第一个 画面 时长 音量 下键 进...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4024994788689450</td>\n",
       "      <td>3</td>\n",
       "      <td>customer</td>\n",
       "      <td>长 音量 下键 安全 模式 出不来</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4024994788689450</td>\n",
       "      <td>4</td>\n",
       "      <td>helpdesk</td>\n",
       "      <td>您好 请 确保 手机 处于 有电 状态 手机 充电 时 充电 指示灯 会 闪烁 保持 充电 ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  round    sender  \\\n",
       "0   4227729258237820      1  customer   \n",
       "1   4227729258237820      2  helpdesk   \n",
       "2   4227729258237820      3  customer   \n",
       "3   4227729258237820      4  helpdesk   \n",
       "4   4121001149457180      1  customer   \n",
       "5   4121001149457180      2  helpdesk   \n",
       "6   4121001149457180      3  customer   \n",
       "7   4121001149457180      4  helpdesk   \n",
       "8   4121001149457180      5  customer   \n",
       "9   4121001149457180      6  helpdesk   \n",
       "10  4121001149457180      7  customer   \n",
       "11  4220041064492650      1  customer   \n",
       "12  4220041064492650      2  helpdesk   \n",
       "13  4220041064492650      3  customer   \n",
       "14  4220041064492650      4  helpdesk   \n",
       "15  4220041064492650      5  customer   \n",
       "16  4024994788689450      1  customer   \n",
       "17  4024994788689450      2  helpdesk   \n",
       "18  4024994788689450      3  customer   \n",
       "19  4024994788689450      4  helpdesk   \n",
       "\n",
       "                                                texts  max_label  round_label  \\\n",
       "0   内涵 段子 联通 皮 点赞 中国联通 中国联通 客服 掌上 营业厅 内涵 段子 话题 封 郑...          3            2   \n",
       "1                                                   u          6            4   \n",
       "2                                                  夸夸          3            0   \n",
       "3                                                   *          6            4   \n",
       "4   距离 反映 问题 已经 一个 星期 花粉 助手 D 荣耀 honor 荣耀 手机 华为 终端...          2            2   \n",
       "5   您好 建议您 先 确认 手机 系统 版本 是否 最新 提示 升级 建议 备份 升 最新 版本...          4            4   \n",
       "6                              遗憾 告诉您 网店 表示 解决不了 皮球 踢          0            0   \n",
       "7                                             亲 去过 售后          4            4   \n",
       "8                                                   *          0            0   \n",
       "9   您好 心情 D 非常 理解 请 放心 D 会 尽我所能 帮 解决问题 烦请 私信 留下 联系...          4            4   \n",
       "10                                                 已经          0            0   \n",
       "11  锤子 科技 客服 昨晚 优酷 电影 声音 会 自动 变 划 最大值 拉 拉 不住 转换 静音...          2            2   \n",
       "12  抱歉 使用 带来 不便 佩戴 耳机 时 出现 情况 可能 线控 异常 所致 进入 设置 全局...          4            4   \n",
       "13                                            木有 带 耳机          0            0   \n",
       "14  未 佩戴 耳机 出现 情况 请 重启 手机 是否 有所改善 无效 重要 数据 保存 电脑 中...          5            4   \n",
       "15                                        当时 恐怖片 太 吓人          0            0   \n",
       "16  您好 请问 华为 7i 升级 完 以后 开 不了 机是 情况 震动 一下 华为 页面 黑屏 ...          2            2   \n",
       "17  您好 手机 反复 重启 进入 不了 界面 请 开机 显示 第一个 画面 时长 音量 下键 进...          4            4   \n",
       "18                                  长 音量 下键 安全 模式 出不来          0            0   \n",
       "19  您好 请 确保 手机 处于 有电 状态 手机 充电 时 充电 指示灯 会 闪烁 保持 充电 ...          4            4   \n",
       "\n",
       "        CNUG     CNUG*     CNUG0      CNaN      HNUG     HNUG*      HNaN  \\\n",
       "0   0.052632  0.000000  0.157895  0.789474  0.000000  0.000000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  0.000000  0.157895  0.000000  0.842105   \n",
       "2   0.157895  0.000000  0.000000  0.842105  0.000000  0.000000  0.000000   \n",
       "3   0.000000  0.000000  0.000000  0.000000  0.157895  0.000000  0.842105   \n",
       "4   0.052632  0.000000  0.789474  0.157895  0.000000  0.000000  0.000000   \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.526316  0.105263  0.368421   \n",
       "6   0.631579  0.000000  0.052632  0.315789  0.000000  0.000000  0.000000   \n",
       "7   0.000000  0.000000  0.000000  0.000000  0.684211  0.000000  0.315789   \n",
       "8   0.684211  0.000000  0.000000  0.315789  0.000000  0.000000  0.000000   \n",
       "9   0.000000  0.000000  0.000000  0.000000  0.578947  0.000000  0.421053   \n",
       "10  0.578947  0.000000  0.000000  0.421053  0.000000  0.000000  0.000000   \n",
       "11  0.000000  0.000000  0.947368  0.052632  0.000000  0.000000  0.000000   \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.578947  0.315789  0.105263   \n",
       "13  0.842105  0.000000  0.000000  0.157895  0.000000  0.000000  0.000000   \n",
       "14  0.000000  0.000000  0.000000  0.000000  0.473684  0.473684  0.052632   \n",
       "15  0.421053  0.105263  0.000000  0.473684  0.000000  0.000000  0.000000   \n",
       "16  0.000000  0.000000  1.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "17  0.000000  0.000000  0.000000  0.000000  0.578947  0.368421  0.052632   \n",
       "18  0.947368  0.000000  0.000000  0.052632  0.000000  0.000000  0.000000   \n",
       "19  0.000000  0.000000  0.000000  0.000000  0.578947  0.421053  0.000000   \n",
       "\n",
       "    sender_num  \n",
       "0            0  \n",
       "1            1  \n",
       "2            0  \n",
       "3            1  \n",
       "4            0  \n",
       "5            1  \n",
       "6            0  \n",
       "7            1  \n",
       "8            0  \n",
       "9            1  \n",
       "10           0  \n",
       "11           0  \n",
       "12           1  \n",
       "13           0  \n",
       "14           1  \n",
       "15           0  \n",
       "16           0  \n",
       "17           1  \n",
       "18           0  \n",
       "19           1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = []\n",
    "for i in df['sender']:\n",
    "    if i == 'customer':\n",
    "        tmp.append(0)\n",
    "    else:\n",
    "        tmp.append(1)\n",
    "df['sender_num'] = tmp\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_df = df[['id','round','sender','texts','max_label','round_label','CNUG','CNUG*','CNUG0','CNaN']]\n",
    "# h_df = df[['id','round','sender','texts','max_label','round_label','HNUG','HNUG*','HNaN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17155, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# h_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import Convolution1D, Flatten, Dropout, MaxPool1D, GlobalAveragePooling1D\n",
    "from keras.layers import concatenate\n",
    "from keras import initializers\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "# from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = df[0:1754]\n",
    "train = df[1755:]\n",
    "\n",
    "X_train = train.filter(['round','sender_num','round_label','texts'])\n",
    "X_test = dev.filter(['round','sender_num','round_label','texts'])\n",
    "y_train_c = train.filter(['CNUG','CNUG*','CNUG0','CNaN'])\n",
    "y_test_c = dev.filter(['CNUG','CNUG*','CNUG0','CNaN'])\n",
    "y_train_h = train.filter(['HNUG','HNUG*','HNaN'])\n",
    "y_test_h = dev.filter(['HNUG','HNUG*','HNaN'])\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15400\n"
     ]
    }
   ],
   "source": [
    "X1_train = X_train['texts']\n",
    "#     X1_train = X_train[:,[-1]]\n",
    "X1_train = [str (item) for item in X1_train]\n",
    "    \n",
    "X1_test = X_test['texts']\n",
    "#     X1_test = X_test[:,[-1]]\n",
    "X1_test = [str (item) for item in X1_test]\n",
    "\n",
    "X2_train = X_train[['round','sender_num','round_label']].values\n",
    "#     X2_train = X_train[:,0:7]\n",
    "X2_test = X_test[['round','sender_num','round_label']].values\n",
    "#     X2_test = X_test[:,0:7]\n",
    "    \n",
    "token = Tokenizer(num_words = 20000)\n",
    "token.fit_on_texts(X1_train)\n",
    "vocab = token.word_index\n",
    "print(token.document_count)\n",
    "\n",
    "x_train_seq = token.texts_to_sequences(X1_train)\n",
    "x_test_seq = token.texts_to_sequences(X1_test)\n",
    "X1_train = sequence.pad_sequences(x_train_seq, maxlen = 150)\n",
    "X1_test = sequence.pad_sequences(x_test_seq, maxlen = 150)\n",
    "\n",
    "#     y_one_train = np_utils.to_categorical(y_train)\n",
    "#     y_one_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. DNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(X1_train, X2_train, X1_test, X2_test, y_train, y_test, loss='categorical_crossentropy'):\n",
    "    \n",
    "    num_labels = 7\n",
    "    main_input = Input(shape=(150,), dtype='float64')\n",
    "\n",
    "    sub_input = Input(shape=(3,))\n",
    "    \n",
    "    # pre-train embeddings\n",
    "    # embedder = Embedding(len(vocab) + 1, 300, input_length = 20, weights = [embedding_matrix], trainable = False)\n",
    "    # embed = embedder(main_input)\n",
    "    embed = Embedding(len(vocab)+1, 300, input_length=150)(main_input)\n",
    "    # filter size, region size\n",
    "    cnn = Convolution1D(2, 2, padding='same', strides = 1, activation='relu')(embed)\n",
    "    cnn = MaxPool1D(pool_size=4)(cnn)\n",
    "    flat = Flatten()(cnn)\n",
    "    drop = Dropout(0.2)(flat)\n",
    "    # main_output = Dense(num_labels, activation='sigmoid')(drop)\n",
    "\n",
    "\n",
    "    dense_1 = Dense(units=256,activation='relu')(sub_input)\n",
    "    drop_1 = Dropout(0.35)(dense_1)\n",
    "    dense_2 = Dense(units=128,activation='relu')(drop_1)\n",
    "    # sub_output = Dense(units=2,activation='sigmoid')(dense_2)\n",
    "\n",
    "    merge = concatenate([drop, dense_2])\n",
    "    dense_3 = Dense(units=10, activation='relu')(merge)\n",
    "    output = Dense(units=7, activation='softmax')(dense_3)\n",
    "\n",
    "    model = Model(inputs=[main_input, sub_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    # checkpoint\n",
    "    # filepath=\"C:/Users/doudi/OneDrive/Documents/TMU-GIDS/Lab/Competition/AI cup 2019/weights.best.hdf5\"\n",
    "    # checkpoint= ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    train_history = model.fit(x=[X1_train, X2_train], y=y_train, epochs=10, \n",
    "                              batch_size=64, verbose=2, validation_split=0.2)\n",
    "\n",
    "    score = model.evaluate(x=[X1_test, X2_test], y=y_test, verbose=1)\n",
    "\n",
    "    print(\"Test Score:\", score[0])\n",
    "    print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "    pre_probability = model.predict(x=[X1_test, X2_test])\n",
    "    predicted = pre_probability.argmax(axis=-1)\n",
    "    \n",
    "    return train_history, pre_probability\n",
    "    '''\n",
    "    from sklearn import metrics\n",
    "    print(\"Classification report for classifier:\\n%s\\n\"\n",
    "          % ( metrics.classification_report(y_test, predicted)))\n",
    "\n",
    "    print(\"f1_score :\\n%s\\n\" % ( metrics.f1_score(y_test, predicted, average='macro')))\n",
    "    print(\"acc_score :\\n%s\\n\" % ( metrics.accuracy_score(y_test, predicted)))\n",
    "    '''\n",
    "\n",
    "def lstm(X1_train, X2_train, X1_test, X2_test, y_train, y_test, loss='categorical_crossentropy'):\n",
    "     \n",
    "    main_input = Input(shape=(150,), dtype='float64')\n",
    "    sub_input = Input(shape=(3,))\n",
    "    \n",
    "    embed = Embedding(output_dim=32,input_dim=20000,input_length=150)(main_input)\n",
    "    dropout_1 = Dropout(0.35)(embed)\n",
    "    lst = LSTM(units=16)(dropout_1)\n",
    "    dense_1 = Dense(units=256,activation='relu')(lst)\n",
    "    dropout_2 = Dropout(0.35)(dense_1)\n",
    "    dense_2 = Dense(units=128,activation='relu')(dropout_2)\n",
    "    dense_3 = Dense(units=7,activation='softmax')(dense_2)\n",
    "\n",
    "\n",
    "    dense_4 = Dense(units=256,activation='relu')(sub_input)\n",
    "    dropout_3 = Dropout(0.35)(dense_4)\n",
    "    dense_5 = Dense(units=128,activation='relu')(dropout_3)\n",
    "    # sub_output = Dense(units=2,activation='sigmoid')(dense_2)\n",
    "\n",
    "    merge = concatenate([dense_3, dense_5])\n",
    "    dense_6 = Dense(units=10, activation='relu')(merge)\n",
    "    output = Dense(units=7, activation='softmax')(dense_6)\n",
    "\n",
    "    model = Model(inputs=[main_input, sub_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    # checkpoint\n",
    "    # filepath=\"C:/Users/doudi/OneDrive/Documents/TMU-GIDS/Lab/Competition/AI cup 2019/weights.best.hdf5\"\n",
    "    # checkpoint= ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    train_history = model.fit(x=[X1_train, X2_train], y=y_train, epochs=10, \n",
    "                              batch_size=64, verbose=2, validation_split=0.2)\n",
    "\n",
    "    score = model.evaluate(x=[X1_test, X2_test], y=y_test, verbose=1)\n",
    "\n",
    "    print(\"Test Score:\", score[0])\n",
    "    print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "    pre_probability = model.predict(x=[X1_test, X2_test])\n",
    "    predicted = pre_probability.argmax(axis=-1)\n",
    "    \n",
    "    return train_history, pre_probability\n",
    "    '''\n",
    "    from sklearn import metrics\n",
    "    print(\"Classification report for classifier:\\n%s\\n\"\n",
    "          % ( metrics.classification_report(y_test, predicted)))\n",
    "\n",
    "    print(\"f1_score :\\n%s\\n\" % ( metrics.f1_score(y_test, predicted, average='macro')))\n",
    "    print(\"acc_score :\\n%s\\n\" % ( metrics.accuracy_score(y_test, predicted)))\n",
    "    '''\n",
    "\n",
    "def CNN_C(X1_train, X2_train, X1_test, X2_test, y_train, y_test, loss='categorical_crossentropy'):\n",
    "    \n",
    "    num_labels = 4\n",
    "    main_input = Input(shape=(150,), dtype='float64')\n",
    "\n",
    "    sub_input = Input(shape=(3,))\n",
    "    \n",
    "    # pre-train embeddings\n",
    "    # embedder = Embedding(len(vocab) + 1, 300, input_length = 20, weights = [embedding_matrix], trainable = False)\n",
    "    # embed = embedder(main_input)\n",
    "    embed = Embedding(len(vocab)+1, 300, input_length=150)(main_input)\n",
    "    # filter size, region size\n",
    "    cnn = Convolution1D(2, 2, padding='same', strides = 1, activation='relu')(embed)\n",
    "    cnn = MaxPool1D(pool_size=4)(cnn)\n",
    "    flat = Flatten()(cnn)\n",
    "    drop = Dropout(0.2)(flat)\n",
    "    # main_output = Dense(num_labels, activation='sigmoid')(drop)\n",
    "\n",
    "\n",
    "    dense_1 = Dense(units=256,activation='relu')(sub_input)\n",
    "    drop_1 = Dropout(0.35)(dense_1)\n",
    "    dense_2 = Dense(units=128,activation='relu')(drop_1)\n",
    "    # sub_output = Dense(units=2,activation='sigmoid')(dense_2)\n",
    "\n",
    "    merge = concatenate([drop, dense_2])\n",
    "    dense_3 = Dense(units=10, activation='relu')(merge)\n",
    "    output = Dense(units=4, activation='softmax')(dense_3)\n",
    "\n",
    "    model = Model(inputs=[main_input, sub_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    # checkpoint\n",
    "    # filepath=\"C:/Users/doudi/OneDrive/Documents/TMU-GIDS/Lab/Competition/AI cup 2019/weights.best.hdf5\"\n",
    "    # checkpoint= ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    train_history = model.fit(x=[X1_train, X2_train], y=y_train, epochs=10, \n",
    "                              batch_size=64, verbose=2, validation_split=0.2)\n",
    "\n",
    "    score = model.evaluate(x=[X1_test, X2_test], y=y_test, verbose=1)\n",
    "\n",
    "    print(\"Test Score:\", score[0])\n",
    "    print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "    pre_probability = model.predict(x=[X1_test, X2_test])\n",
    "    predicted = pre_probability.argmax(axis=-1)\n",
    "    \n",
    "    return train_history, pre_probability\n",
    "    '''\n",
    "    from sklearn import metrics\n",
    "    print(\"Classification report for classifier:\\n%s\\n\"\n",
    "          % ( metrics.classification_report(y_test, predicted)))\n",
    "\n",
    "    print(\"f1_score :\\n%s\\n\" % ( metrics.f1_score(y_test, predicted, average='macro')))\n",
    "    print(\"acc_score :\\n%s\\n\" % ( metrics.accuracy_score(y_test, predicted)))\n",
    "    '''\n",
    "\n",
    "def lstm_C(X1_train, X2_train, X1_test, X2_test, y_train, y_test, loss='categorical_crossentropy'):\n",
    "     \n",
    "    main_input = Input(shape=(150,), dtype='float64')\n",
    "    sub_input = Input(shape=(3,))\n",
    "    \n",
    "    embed = Embedding(output_dim=32,input_dim=20000,input_length=150)(main_input)\n",
    "    dropout_1 = Dropout(0.35)(embed)\n",
    "    lst = LSTM(units=16)(dropout_1)\n",
    "    dense_1 = Dense(units=256,activation='relu')(lst)\n",
    "    dropout_2 = Dropout(0.35)(dense_1)\n",
    "    dense_2 = Dense(units=128,activation='relu')(dropout_2)\n",
    "    dense_3 = Dense(units=4,activation='softmax')(dense_2)\n",
    "\n",
    "\n",
    "    dense_4 = Dense(units=256,activation='relu')(sub_input)\n",
    "    dropout_3 = Dropout(0.35)(dense_4)\n",
    "    dense_5 = Dense(units=128,activation='relu')(dropout_3)\n",
    "    # sub_output = Dense(units=2,activation='sigmoid')(dense_2)\n",
    "\n",
    "    merge = concatenate([dense_3, dense_5])\n",
    "    dense_6 = Dense(units=10, activation='relu')(merge)\n",
    "    output = Dense(units=4, activation='softmax')(dense_6)\n",
    "\n",
    "    model = Model(inputs=[main_input, sub_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    # checkpoint\n",
    "    # filepath=\"C:/Users/doudi/OneDrive/Documents/TMU-GIDS/Lab/Competition/AI cup 2019/weights.best.hdf5\"\n",
    "    # checkpoint= ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    train_history = model.fit(x=[X1_train, X2_train], y=y_train, epochs=10, \n",
    "                              batch_size=64, verbose=2, validation_split=0.2)\n",
    "\n",
    "    score = model.evaluate(x=[X1_test, X2_test], y=y_test, verbose=1)\n",
    "\n",
    "    print(\"Test Score:\", score[0])\n",
    "    print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "    pre_probability = model.predict(x=[X1_test, X2_test])\n",
    "    predicted = pre_probability.argmax(axis=-1)\n",
    "    \n",
    "    return train_history, pre_probability\n",
    "    '''\n",
    "    from sklearn import metrics\n",
    "    print(\"Classification report for classifier:\\n%s\\n\"\n",
    "          % ( metrics.classification_report(y_test, predicted)))\n",
    "\n",
    "    print(\"f1_score :\\n%s\\n\" % ( metrics.f1_score(y_test, predicted, average='macro')))\n",
    "    print(\"acc_score :\\n%s\\n\" % ( metrics.accuracy_score(y_test, predicted)))\n",
    "    '''\n",
    "\n",
    "    \n",
    "def CNN_H(X1_train, X2_train, X1_test, X2_test, y_train, y_test, loss='categorical_crossentropy'):\n",
    "    \n",
    "    num_labels = 3\n",
    "    main_input = Input(shape=(150,), dtype='float64')\n",
    "\n",
    "    sub_input = Input(shape=(3,))\n",
    "    \n",
    "    # pre-train embeddings\n",
    "    # embedder = Embedding(len(vocab) + 1, 300, input_length = 20, weights = [embedding_matrix], trainable = False)\n",
    "    # embed = embedder(main_input)\n",
    "    embed = Embedding(len(vocab)+1, 300, input_length=150)(main_input)\n",
    "    # filter size, region size\n",
    "    cnn = Convolution1D(2, 2, padding='same', strides = 1, activation='relu')(embed)\n",
    "    cnn = MaxPool1D(pool_size=4)(cnn)\n",
    "    flat = Flatten()(cnn)\n",
    "    drop = Dropout(0.2)(flat)\n",
    "    # main_output = Dense(num_labels, activation='sigmoid')(drop)\n",
    "\n",
    "\n",
    "    dense_1 = Dense(units=256,activation='relu')(sub_input)\n",
    "    drop_1 = Dropout(0.35)(dense_1)\n",
    "    dense_2 = Dense(units=128,activation='relu')(drop_1)\n",
    "    # sub_output = Dense(units=2,activation='sigmoid')(dense_2)\n",
    "\n",
    "    merge = concatenate([drop, dense_2])\n",
    "    dense_3 = Dense(units=10, activation='relu')(merge)\n",
    "    output = Dense(units=3, activation='softmax')(dense_3)\n",
    "\n",
    "    model = Model(inputs=[main_input, sub_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    # checkpoint\n",
    "    # filepath=\"C:/Users/doudi/OneDrive/Documents/TMU-GIDS/Lab/Competition/AI cup 2019/weights.best.hdf5\"\n",
    "    # checkpoint= ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    train_history = model.fit(x=[X1_train, X2_train], y=y_train, epochs=10, \n",
    "                              batch_size=64, verbose=2, validation_split=0.2)\n",
    "\n",
    "    score = model.evaluate(x=[X1_test, X2_test], y=y_test, verbose=1)\n",
    "\n",
    "    print(\"Test Score:\", score[0])\n",
    "    print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "    pre_probability = model.predict(x=[X1_test, X2_test])\n",
    "    predicted = pre_probability.argmax(axis=-1)\n",
    "    \n",
    "    return train_history, pre_probability\n",
    "    '''\n",
    "    from sklearn import metrics\n",
    "    print(\"Classification report for classifier:\\n%s\\n\"\n",
    "          % ( metrics.classification_report(y_test, predicted)))\n",
    "\n",
    "    print(\"f1_score :\\n%s\\n\" % ( metrics.f1_score(y_test, predicted, average='macro')))\n",
    "    print(\"acc_score :\\n%s\\n\" % ( metrics.accuracy_score(y_test, predicted)))\n",
    "    '''\n",
    "\n",
    "def lstm_H(X1_train, X2_train, X1_test, X2_test, y_train, y_test, loss='categorical_crossentropy'):\n",
    "     \n",
    "    main_input = Input(shape=(150,), dtype='float64')\n",
    "    sub_input = Input(shape=(3,))\n",
    "    \n",
    "    embed = Embedding(output_dim=32,input_dim=20000,input_length=150)(main_input)\n",
    "    dropout_1 = Dropout(0.35)(embed)\n",
    "    lst = LSTM(units=16)(dropout_1)\n",
    "    dense_1 = Dense(units=256,activation='relu')(lst)\n",
    "    dropout_2 = Dropout(0.35)(dense_1)\n",
    "    dense_2 = Dense(units=128,activation='relu')(dropout_2)\n",
    "    dense_3 = Dense(units=3,activation='softmax')(dense_2)\n",
    "\n",
    "\n",
    "    dense_4 = Dense(units=256,activation='relu')(sub_input)\n",
    "    dropout_3 = Dropout(0.35)(dense_4)\n",
    "    dense_5 = Dense(units=128,activation='relu')(dropout_3)\n",
    "    # sub_output = Dense(units=2,activation='sigmoid')(dense_2)\n",
    "\n",
    "    merge = concatenate([dense_3, dense_5])\n",
    "    dense_6 = Dense(units=10, activation='relu')(merge)\n",
    "    output = Dense(units=3, activation='softmax')(dense_6)\n",
    "\n",
    "    model = Model(inputs=[main_input, sub_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    # checkpoint\n",
    "    # filepath=\"C:/Users/doudi/OneDrive/Documents/TMU-GIDS/Lab/Competition/AI cup 2019/weights.best.hdf5\"\n",
    "    # checkpoint= ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    train_history = model.fit(x=[X1_train, X2_train], y=y_train, epochs=10, \n",
    "                              batch_size=64, verbose=2, validation_split=0.2)\n",
    "\n",
    "    score = model.evaluate(x=[X1_test, X2_test], y=y_test, verbose=1)\n",
    "\n",
    "    print(\"Test Score:\", score[0])\n",
    "    print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "    pre_probability = model.predict(x=[X1_test, X2_test])\n",
    "    predicted = pre_probability.argmax(axis=-1)\n",
    "    \n",
    "    return train_history, pre_probability\n",
    "    '''\n",
    "    from sklearn import metrics\n",
    "    print(\"Classification report for classifier:\\n%s\\n\"\n",
    "          % ( metrics.classification_report(y_test, predicted)))\n",
    "\n",
    "    print(\"f1_score :\\n%s\\n\" % ( metrics.f1_score(y_test, predicted, average='macro')))\n",
    "    print(\"acc_score :\\n%s\\n\" % ( metrics.accuracy_score(y_test, predicted)))\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_folds = 3\\nmodel_history = []\\nfor i in tqdm(range(n_folds)):\\n    print(\"Training on Fold: \",i+1)\\n    from sklearn.model_selection import train_test_split\\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, \\n                                                        random_state = np.random.randint(1,1000, 1)[0])\\n                                               \\n    \\n    model_history.append(CNN(X_train, X_test, y_train, y_test))\\n    print(\"=======\"*12, end=\"\\n\\n\\n\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "'''\n",
    "n_folds = 3\n",
    "model_history = []\n",
    "for i in tqdm(range(n_folds)):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, \n",
    "                                                        random_state = np.random.randint(1,1000, 1)[0])\n",
    "                                               \n",
    "    \n",
    "    model_history.append(CNN(X_train, X_test, y_train, y_test))\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15400\n",
      "WARNING:tensorflow:From C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 150, 300)     6533100     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 150, 2)       1202        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 37, 2)        0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          1024        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 74)           0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 74)           0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 202)          0           dropout_1[0][0]                  \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           2030        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 7)            77          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,570,329\n",
      "Trainable params: 6,570,329\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 12320 samples, validate on 3080 samples\n",
      "Epoch 1/50\n",
      " - 4s - loss: 1.0006 - accuracy: 0.7784 - val_loss: 0.8348 - val_accuracy: 0.8503\n",
      "Epoch 2/50\n",
      " - 3s - loss: 0.8365 - accuracy: 0.8322 - val_loss: 0.8226 - val_accuracy: 0.8513\n",
      "Epoch 3/50\n",
      " - 3s - loss: 0.8198 - accuracy: 0.8342 - val_loss: 0.8127 - val_accuracy: 0.8532\n",
      "Epoch 4/50\n",
      " - 3s - loss: 0.8067 - accuracy: 0.8358 - val_loss: 0.8082 - val_accuracy: 0.8529\n",
      "Epoch 5/50\n",
      " - 3s - loss: 0.7942 - accuracy: 0.8396 - val_loss: 0.8044 - val_accuracy: 0.8536\n",
      "Epoch 6/50\n",
      " - 3s - loss: 0.7857 - accuracy: 0.8424 - val_loss: 0.8036 - val_accuracy: 0.8506\n",
      "Epoch 7/50\n",
      " - 3s - loss: 0.7815 - accuracy: 0.8429 - val_loss: 0.8049 - val_accuracy: 0.8506\n",
      "Epoch 8/50\n",
      " - 3s - loss: 0.7793 - accuracy: 0.8439 - val_loss: 0.8095 - val_accuracy: 0.8419\n",
      "Epoch 9/50\n",
      " - 3s - loss: 0.7749 - accuracy: 0.8479 - val_loss: 0.8080 - val_accuracy: 0.8539\n",
      "Epoch 10/50\n",
      " - 3s - loss: 0.7737 - accuracy: 0.8476 - val_loss: 0.8055 - val_accuracy: 0.8513\n",
      "Epoch 11/50\n",
      " - 3s - loss: 0.7694 - accuracy: 0.8488 - val_loss: 0.8065 - val_accuracy: 0.8529\n",
      "Epoch 12/50\n",
      " - 3s - loss: 0.7673 - accuracy: 0.8519 - val_loss: 0.8078 - val_accuracy: 0.8484\n",
      "Epoch 13/50\n",
      " - 3s - loss: 0.7659 - accuracy: 0.8502 - val_loss: 0.8060 - val_accuracy: 0.8510\n",
      "Epoch 14/50\n",
      " - 2s - loss: 0.7651 - accuracy: 0.8483 - val_loss: 0.8068 - val_accuracy: 0.8503\n",
      "Epoch 15/50\n",
      " - 3s - loss: 0.7635 - accuracy: 0.8515 - val_loss: 0.8075 - val_accuracy: 0.8497\n",
      "Epoch 16/50\n",
      " - 3s - loss: 0.7616 - accuracy: 0.8541 - val_loss: 0.8066 - val_accuracy: 0.8539\n",
      "Epoch 17/50\n",
      " - 3s - loss: 0.7592 - accuracy: 0.8538 - val_loss: 0.8088 - val_accuracy: 0.8468\n",
      "Epoch 18/50\n",
      " - 3s - loss: 0.7595 - accuracy: 0.8550 - val_loss: 0.8088 - val_accuracy: 0.8588\n",
      "Epoch 19/50\n",
      " - 3s - loss: 0.7587 - accuracy: 0.8542 - val_loss: 0.8113 - val_accuracy: 0.8461\n",
      "Epoch 20/50\n",
      " - 3s - loss: 0.7583 - accuracy: 0.8568 - val_loss: 0.8104 - val_accuracy: 0.8519\n",
      "Epoch 21/50\n",
      " - 3s - loss: 0.7565 - accuracy: 0.8550 - val_loss: 0.8107 - val_accuracy: 0.8474\n",
      "Epoch 22/50\n",
      " - 3s - loss: 0.7565 - accuracy: 0.8544 - val_loss: 0.8094 - val_accuracy: 0.8468\n",
      "Epoch 23/50\n",
      " - 3s - loss: 0.7553 - accuracy: 0.8563 - val_loss: 0.8110 - val_accuracy: 0.8591\n",
      "Epoch 24/50\n",
      " - 3s - loss: 0.7549 - accuracy: 0.8574 - val_loss: 0.8135 - val_accuracy: 0.8487\n",
      "Epoch 25/50\n",
      " - 3s - loss: 0.7536 - accuracy: 0.8559 - val_loss: 0.8097 - val_accuracy: 0.8519\n",
      "Epoch 26/50\n",
      " - 3s - loss: 0.7534 - accuracy: 0.8585 - val_loss: 0.8117 - val_accuracy: 0.8542\n",
      "Epoch 27/50\n",
      " - 3s - loss: 0.7529 - accuracy: 0.8587 - val_loss: 0.8109 - val_accuracy: 0.8571\n",
      "Epoch 28/50\n",
      " - 3s - loss: 0.7526 - accuracy: 0.8612 - val_loss: 0.8156 - val_accuracy: 0.8545\n",
      "Epoch 29/50\n",
      " - 3s - loss: 0.7519 - accuracy: 0.8598 - val_loss: 0.8165 - val_accuracy: 0.8500\n",
      "Epoch 30/50\n",
      " - 3s - loss: 0.7511 - accuracy: 0.8572 - val_loss: 0.8142 - val_accuracy: 0.8532\n",
      "Epoch 31/50\n",
      " - 3s - loss: 0.7512 - accuracy: 0.8555 - val_loss: 0.8140 - val_accuracy: 0.8539\n",
      "Epoch 32/50\n",
      " - 3s - loss: 0.7495 - accuracy: 0.8593 - val_loss: 0.8201 - val_accuracy: 0.8471\n",
      "Epoch 33/50\n",
      " - 3s - loss: 0.7503 - accuracy: 0.8597 - val_loss: 0.8144 - val_accuracy: 0.8429\n",
      "Epoch 34/50\n",
      " - 3s - loss: 0.7510 - accuracy: 0.8585 - val_loss: 0.8174 - val_accuracy: 0.8568\n",
      "Epoch 35/50\n",
      " - 3s - loss: 0.7493 - accuracy: 0.8626 - val_loss: 0.8197 - val_accuracy: 0.8571\n",
      "Epoch 36/50\n",
      " - 3s - loss: 0.7497 - accuracy: 0.8588 - val_loss: 0.8161 - val_accuracy: 0.8568\n",
      "Epoch 37/50\n",
      " - 3s - loss: 0.7494 - accuracy: 0.8603 - val_loss: 0.8188 - val_accuracy: 0.8477\n",
      "Epoch 38/50\n",
      " - 3s - loss: 0.7492 - accuracy: 0.8597 - val_loss: 0.8203 - val_accuracy: 0.8604\n",
      "Epoch 39/50\n",
      " - 3s - loss: 0.7476 - accuracy: 0.8636 - val_loss: 0.8167 - val_accuracy: 0.8419\n",
      "Epoch 40/50\n",
      " - 3s - loss: 0.7477 - accuracy: 0.8628 - val_loss: 0.8194 - val_accuracy: 0.8477\n",
      "Epoch 41/50\n",
      " - 3s - loss: 0.7476 - accuracy: 0.8627 - val_loss: 0.8203 - val_accuracy: 0.8575\n",
      "Epoch 42/50\n",
      " - 3s - loss: 0.7477 - accuracy: 0.8602 - val_loss: 0.8194 - val_accuracy: 0.8461\n",
      "Epoch 43/50\n",
      " - 3s - loss: 0.7476 - accuracy: 0.8621 - val_loss: 0.8258 - val_accuracy: 0.8539\n",
      "Epoch 44/50\n",
      " - 3s - loss: 0.7477 - accuracy: 0.8590 - val_loss: 0.8212 - val_accuracy: 0.8539\n",
      "Epoch 45/50\n",
      " - 3s - loss: 0.7462 - accuracy: 0.8636 - val_loss: 0.8235 - val_accuracy: 0.8516\n",
      "Epoch 46/50\n",
      " - 3s - loss: 0.7462 - accuracy: 0.8626 - val_loss: 0.8236 - val_accuracy: 0.8555\n",
      "Epoch 47/50\n",
      " - 3s - loss: 0.7469 - accuracy: 0.8611 - val_loss: 0.8213 - val_accuracy: 0.8532\n",
      "Epoch 48/50\n",
      " - 3s - loss: 0.7470 - accuracy: 0.8627 - val_loss: 0.8247 - val_accuracy: 0.8481\n",
      "Epoch 49/50\n",
      " - 3s - loss: 0.7462 - accuracy: 0.8640 - val_loss: 0.8257 - val_accuracy: 0.8536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      " - 2s - loss: 0.7470 - accuracy: 0.8622 - val_loss: 0.8228 - val_accuracy: 0.8458\n",
      "1754/1754 [==============================] - 0s 59us/step\n",
      "Test Score: 0.8152590429361489\n",
      "Test Accuracy: 0.8472064137458801\n"
     ]
    }
   ],
   "source": [
    "# use categorical_crossentropy as loss function\n",
    "train_history , pred = CNN(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15400\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 150, 32)      640000      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 150, 32)      0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 16)           3136        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          4352        lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          1024        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          32896       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 7)            903         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          32896       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 135)          0           dense_7[0][0]                    \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 10)           1360        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 7)            77          dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 716,644\n",
      "Trainable params: 716,644\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 12320 samples, validate on 3080 samples\n",
      "Epoch 1/50\n",
      " - 25s - loss: 1.0567 - accuracy: 0.7787 - val_loss: 0.8244 - val_accuracy: 0.8497\n",
      "Epoch 2/50\n",
      " - 27s - loss: 0.8241 - accuracy: 0.8309 - val_loss: 0.8053 - val_accuracy: 0.8536\n",
      "Epoch 3/50\n",
      " - 26s - loss: 0.8019 - accuracy: 0.8435 - val_loss: 0.7940 - val_accuracy: 0.8666\n",
      "Epoch 4/50\n",
      " - 26s - loss: 0.7871 - accuracy: 0.8562 - val_loss: 0.7941 - val_accuracy: 0.8575\n",
      "Epoch 5/50\n",
      " - 26s - loss: 0.7737 - accuracy: 0.8590 - val_loss: 0.7954 - val_accuracy: 0.8646\n",
      "Epoch 6/50\n",
      " - 26s - loss: 0.7623 - accuracy: 0.8640 - val_loss: 0.7838 - val_accuracy: 0.8792\n",
      "Epoch 7/50\n",
      " - 27s - loss: 0.7545 - accuracy: 0.8772 - val_loss: 0.7810 - val_accuracy: 0.8786\n",
      "Epoch 8/50\n",
      " - 26s - loss: 0.7470 - accuracy: 0.8843 - val_loss: 0.7818 - val_accuracy: 0.8760\n",
      "Epoch 9/50\n",
      " - 29s - loss: 0.7410 - accuracy: 0.8877 - val_loss: 0.7799 - val_accuracy: 0.8756\n",
      "Epoch 10/50\n",
      " - 26s - loss: 0.7349 - accuracy: 0.8898 - val_loss: 0.7833 - val_accuracy: 0.8666\n",
      "Epoch 11/50\n",
      " - 27s - loss: 0.7309 - accuracy: 0.8904 - val_loss: 0.7822 - val_accuracy: 0.8705\n",
      "Epoch 12/50\n",
      " - 27s - loss: 0.7268 - accuracy: 0.8962 - val_loss: 0.7814 - val_accuracy: 0.8610\n",
      "Epoch 13/50\n",
      " - 27s - loss: 0.7238 - accuracy: 0.8964 - val_loss: 0.7806 - val_accuracy: 0.8731\n",
      "Epoch 14/50\n",
      " - 27s - loss: 0.7196 - accuracy: 0.8985 - val_loss: 0.7837 - val_accuracy: 0.8698\n",
      "Epoch 15/50\n",
      " - 27s - loss: 0.7181 - accuracy: 0.9052 - val_loss: 0.7789 - val_accuracy: 0.8808\n",
      "Epoch 16/50\n",
      " - 26s - loss: 0.7169 - accuracy: 0.9018 - val_loss: 0.7800 - val_accuracy: 0.8705\n",
      "Epoch 17/50\n",
      " - 26s - loss: 0.7138 - accuracy: 0.9047 - val_loss: 0.7873 - val_accuracy: 0.8237\n",
      "Epoch 18/50\n",
      " - 27s - loss: 0.7121 - accuracy: 0.9090 - val_loss: 0.7821 - val_accuracy: 0.8688\n",
      "Epoch 19/50\n",
      " - 29s - loss: 0.7111 - accuracy: 0.9090 - val_loss: 0.7769 - val_accuracy: 0.8591\n",
      "Epoch 20/50\n",
      " - 27s - loss: 0.7093 - accuracy: 0.9114 - val_loss: 0.7847 - val_accuracy: 0.8581\n",
      "Epoch 21/50\n",
      " - 24s - loss: 0.7073 - accuracy: 0.9140 - val_loss: 0.7797 - val_accuracy: 0.8542\n",
      "Epoch 22/50\n",
      " - 25s - loss: 0.7059 - accuracy: 0.9148 - val_loss: 0.7842 - val_accuracy: 0.8474\n",
      "Epoch 23/50\n",
      " - 24s - loss: 0.7051 - accuracy: 0.9176 - val_loss: 0.7841 - val_accuracy: 0.8649\n",
      "Epoch 24/50\n",
      " - 26s - loss: 0.7032 - accuracy: 0.9174 - val_loss: 0.7891 - val_accuracy: 0.8545\n",
      "Epoch 25/50\n",
      " - 26s - loss: 0.7026 - accuracy: 0.9184 - val_loss: 0.7911 - val_accuracy: 0.8568\n",
      "Epoch 26/50\n",
      " - 24s - loss: 0.7010 - accuracy: 0.9218 - val_loss: 0.7883 - val_accuracy: 0.8555\n",
      "Epoch 27/50\n",
      " - 26s - loss: 0.7000 - accuracy: 0.9204 - val_loss: 0.7882 - val_accuracy: 0.8510\n",
      "Epoch 28/50\n"
     ]
    }
   ],
   "source": [
    "# use categorical_crossentropy as loss function\n",
    "train_history_ls , pred_ls = lstm(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use jsd as loss function\n",
    "train_history_jsd , pred_jsd = CNN(X_train, X_test, y_train, y_test, loss = jsd_custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use jsd as loss function\n",
    "train_history_ls_jsd , pred_ls_jsd = lstm(X_train, X_test, y_train, y_test, loss = jsd_custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use rnss as loss function\n",
    "# train_history_rnss , pred_rnss = CNN(X_train, X_test, y_train, y_test, loss = rnss_custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use rnss as loss function\n",
    "# train_history_ls_rnss , pred_ls_rnss = lstm(X_train, X_test, y_train, y_test, loss = rnss_custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = np.array(y_test)\n",
    "def calculate_divergence(true, pred):\n",
    "    tmp = 0\n",
    "    for i in range(len(true)):\n",
    "        tmp = tmp + jensen_shannon_div(pred[i], true[i])\n",
    "    \n",
    "    print('mean jsd :', tmp/len(true))\n",
    "    \n",
    "    tmp = 0\n",
    "    for i in range(len(true)):\n",
    "        tmp = tmp + root_normalized_squared_error(pred[i], true[i])\n",
    "    \n",
    "    print('mean rnss :', tmp/len(true))\n",
    "    \n",
    "#         print('---sentence{0}---'.format(i))\n",
    "#         print('jsd :', jensen_shannon_div(pred[i], true[i]))\n",
    "#         print('rnss :', root_normalized_squared_error(pred[i], true[i]))\n",
    "\n",
    "# print('--- textCNN ---', '\\n')\n",
    "# calculate_divergence(true, pred)\n",
    "\n",
    "# print('--- LSTM ---', '\\n')\n",
    "# calculate_divergence(true, pred_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== categorical_crossentropy ===', '\\n')\n",
    "print('---textCNN---')\n",
    "calculate_divergence(true, pred)\n",
    "print('---LSTM---')\n",
    "calculate_divergence(true, pred_ls)\n",
    "print('\\n', '=== loss_jsd ===', '\\n')\n",
    "print('---textCNN---')\n",
    "calculate_divergence(true, pred_jsd)\n",
    "print('---LSTM---')\n",
    "calculate_divergence(true, pred_ls_jsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.3635314e-02, 2.3085409e-04, 8.4093058e-01, ..., 2.0889031e-04,\n",
       "        8.8531706e-06, 2.3545331e-04],\n",
       "       [2.8267033e-07, 1.1218920e-06, 5.2591265e-10, ..., 5.0565666e-01,\n",
       "        1.3791247e-01, 3.5642898e-01],\n",
       "       [5.5945146e-01, 1.1985750e-01, 9.3967244e-03, ..., 5.9507645e-05,\n",
       "        1.2362933e-04, 3.6611807e-05],\n",
       "       ...,\n",
       "       [1.8303791e-06, 1.0560428e-06, 1.4783109e-08, ..., 6.1185038e-01,\n",
       "        1.0529692e-01, 2.8284660e-01],\n",
       "       [4.4889548e-01, 2.0985053e-01, 7.1117044e-03, ..., 2.4526957e-05,\n",
       "        7.2622061e-05, 2.2786977e-05],\n",
       "       [1.0568731e-06, 9.7649570e-07, 3.0893015e-09, ..., 5.1087028e-01,\n",
       "        2.0788656e-01, 2.8123870e-01]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_cnn_entropy = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### customer and helpdesk split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 150, 300)     6533100     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 150, 2)       1202        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 37, 2)        0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          1024        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 74)           0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 74)           0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          32896       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 202)          0           dropout_3[0][0]                  \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10)           2030        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4)            44          dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,570,296\n",
      "Trainable params: 6,570,296\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 12320 samples, validate on 3080 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 2.3430 - accuracy: 0.4351 - val_loss: 2.0865 - val_accuracy: 0.4237\n",
      "Epoch 2/10\n",
      " - 3s - loss: 22.0416 - accuracy: 0.3839 - val_loss: 15.4031 - val_accuracy: 0.3542\n",
      "Epoch 3/10\n",
      " - 3s - loss: 84.3991 - accuracy: 0.4264 - val_loss: 38.8479 - val_accuracy: 0.3769\n",
      "Epoch 4/10\n",
      " - 3s - loss: 210.6358 - accuracy: 0.4381 - val_loss: 147.9872 - val_accuracy: 0.8088\n",
      "Epoch 5/10\n",
      " - 3s - loss: 456.5001 - accuracy: 0.4381 - val_loss: 555.1094 - val_accuracy: 0.2536\n",
      "Epoch 6/10\n",
      " - 3s - loss: 760.0712 - accuracy: 0.4152 - val_loss: 468.0433 - val_accuracy: 0.8140\n",
      "Epoch 7/10\n",
      " - 3s - loss: 1078.4414 - accuracy: 0.4193 - val_loss: 673.8203 - val_accuracy: 0.5906\n",
      "Epoch 8/10\n",
      " - 3s - loss: 1479.5035 - accuracy: 0.4249 - val_loss: 2399.8282 - val_accuracy: 0.2325\n",
      "Epoch 9/10\n",
      " - 3s - loss: 2198.2033 - accuracy: 0.4069 - val_loss: 4420.5460 - val_accuracy: 0.2357\n",
      "Epoch 10/10\n",
      " - 3s - loss: 3491.2661 - accuracy: 0.3815 - val_loss: 9364.3505 - val_accuracy: 0.4386\n",
      "1754/1754 [==============================] - 0s 87us/step\n",
      "Test Score: 9664.98785365593\n",
      "Test Accuracy: 0.432725191116333\n"
     ]
    }
   ],
   "source": [
    "train_history_c , pred_c = CNN_C(X1_train, X2_train, X1_test, X2_test, y_train_c, y_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history_h , pred_h = CNN_H(X1_train, X2_train, X1_test, X2_test, y_train_h, y_test_h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
