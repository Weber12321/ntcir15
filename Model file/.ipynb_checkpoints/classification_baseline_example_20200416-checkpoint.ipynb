{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline classification model (tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(X_TR, X_TE, Y_TR, Y_TE):\n",
    "    \n",
    "    X_TR = tfidf_vectorizer.fit_transform(X_TR)\n",
    "    X_TE = tfidf_vectorizer.transform(X_TE)\n",
    "    \n",
    "    Models = ['Bernoulli NB','Multinomial NB','Svm (linear)','Logistic Regression',\n",
    "              'Random Forest','kNN','Decision Tree','XG Boost']\n",
    "    function = [BernoulliNB(),MultinomialNB(),svm.SVC(kernel=\"linear\"),LogisticRegression(),\n",
    "              RandomForestClassifier(),KNeighborsClassifier(),DecisionTreeClassifier(),\n",
    "                XGBClassifier()]\n",
    "    perform_f1 = []\n",
    "    perform_acc = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(len(function))):\n",
    "        model = function[i]\n",
    "        #performance = cross_val_score(model, tfidf_vectorizer.fit_transform(x), y, cv=10, scoring'accuracy')\n",
    "        \n",
    "        func = str(function[i])\n",
    "        print(\"==== \", func[0:func.index('(')], \" ====\")\n",
    "\n",
    "        model.fit(X_TR, Y_TR)\n",
    "        model.score(X_TE, Y_TE)\n",
    "        e = Y_TE\n",
    "        p = model.predict(X_TE)\n",
    "        print(metrics.classification_report(e,p))\n",
    "        perform_f1.append(metrics.f1_score(e,p,average='macro'))\n",
    "        perform_acc.append(metrics.accuracy_score(e,p))\n",
    "        \n",
    "    result_f1_table = pd.DataFrame({\"Models\":Models,\"Result f1 scores\":perform_f1})\n",
    "    result_acc_table = pd.DataFrame({\"Models\":Models,\"Result acc scores\":perform_acc})\n",
    "    return result_f1_table, result_acc_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDB\n",
    "path1 = 'C:/Users/doudi/Downloads/'\n",
    "os.chdir(path1)\n",
    "\n",
    "file1 = 'Imdb_Seg_no_stopword.csv'\n",
    "imdb = pd.read_csv(file1)\n",
    "imdb_train = imdb.iloc[0:25000,:]\n",
    "imdb_test = imdb.iloc[25000:,:]\n",
    "\n",
    "# PTT\n",
    "file2 = 'PTT_movie_seg.csv'\n",
    "PTT = pd.read_csv(file2)\n",
    "PTT_train = PTT.iloc[0:2264,:]\n",
    "PTT_test = PTT.iloc[2264:,:]\n",
    "\n",
    "# RE\n",
    "file3 = 'Reader_Emotion_Seg_no_stopword.csv'\n",
    "RE = pd.read_csv(file3)\n",
    "RE['concate'] = RE['title'] + RE['content']\n",
    "RE_train = RE.iloc[0:11671,:]\n",
    "RE_test = RE.iloc[11671:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 74849)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.fit_transform(imdb_train['content']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f96ea80901741359c8c442c27b8a8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====  BernoulliNB  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.84     12500\n",
      "           1       0.87      0.77      0.82     12500\n",
      "\n",
      "    accuracy                           0.83     25000\n",
      "   macro avg       0.83      0.83      0.83     25000\n",
      "weighted avg       0.83      0.83      0.83     25000\n",
      "\n",
      "====  MultinomialNB  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84     12500\n",
      "           1       0.87      0.77      0.82     12500\n",
      "\n",
      "    accuracy                           0.83     25000\n",
      "   macro avg       0.83      0.83      0.83     25000\n",
      "weighted avg       0.83      0.83      0.83     25000\n",
      "\n",
      "====  SVC  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88     12500\n",
      "           1       0.89      0.87      0.88     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n",
      "====  LogisticRegression  ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88     12500\n",
      "           1       0.88      0.88      0.88     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n",
      "====  RandomForestClassifier  ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.75     12500\n",
      "           1       0.78      0.64      0.70     12500\n",
      "\n",
      "    accuracy                           0.73     25000\n",
      "   macro avg       0.74      0.73      0.73     25000\n",
      "weighted avg       0.74      0.73      0.73     25000\n",
      "\n",
      "====  KNeighborsClassifier  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68     12500\n",
      "           1       0.68      0.60      0.64     12500\n",
      "\n",
      "    accuracy                           0.66     25000\n",
      "   macro avg       0.66      0.66      0.66     25000\n",
      "weighted avg       0.66      0.66      0.66     25000\n",
      "\n",
      "====  DecisionTreeClassifier  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.71     12500\n",
      "           1       0.71      0.70      0.70     12500\n",
      "\n",
      "    accuracy                           0.70     25000\n",
      "   macro avg       0.70      0.70      0.70     25000\n",
      "weighted avg       0.70      0.70      0.70     25000\n",
      "\n",
      "====  XGBClassifier  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.75      0.80     12500\n",
      "           1       0.78      0.87      0.82     12500\n",
      "\n",
      "    accuracy                           0.81     25000\n",
      "   macro avg       0.81      0.81      0.81     25000\n",
      "weighted avg       0.81      0.81      0.81     25000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IMDB_output = baseline_model(imdb_train['content'], imdb_test['content'], imdb_train['tag'], imdb_test['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c42258f9d9413688b3ed1d47971a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====  BernoulliNB  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.58      0.70      1132\n",
      "           1       0.69      0.91      0.78      1132\n",
      "\n",
      "    accuracy                           0.75      2264\n",
      "   macro avg       0.78      0.75      0.74      2264\n",
      "weighted avg       0.78      0.75      0.74      2264\n",
      "\n",
      "====  MultinomialNB  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.70      0.78      1132\n",
      "           1       0.75      0.90      0.82      1132\n",
      "\n",
      "    accuracy                           0.80      2264\n",
      "   macro avg       0.81      0.80      0.80      2264\n",
      "weighted avg       0.81      0.80      0.80      2264\n",
      "\n",
      "====  SVC  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88      1132\n",
      "           1       0.87      0.88      0.88      1132\n",
      "\n",
      "    accuracy                           0.88      2264\n",
      "   macro avg       0.88      0.88      0.88      2264\n",
      "weighted avg       0.88      0.88      0.88      2264\n",
      "\n",
      "====  LogisticRegression  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      1132\n",
      "           1       0.83      0.86      0.85      1132\n",
      "\n",
      "    accuracy                           0.84      2264\n",
      "   macro avg       0.84      0.84      0.84      2264\n",
      "weighted avg       0.84      0.84      0.84      2264\n",
      "\n",
      "====  RandomForestClassifier  ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.74      1132\n",
      "           1       0.75      0.73      0.74      1132\n",
      "\n",
      "    accuracy                           0.74      2264\n",
      "   macro avg       0.74      0.74      0.74      2264\n",
      "weighted avg       0.74      0.74      0.74      2264\n",
      "\n",
      "====  KNeighborsClassifier  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.60      0.67      1132\n",
      "           1       0.67      0.82      0.74      1132\n",
      "\n",
      "    accuracy                           0.71      2264\n",
      "   macro avg       0.72      0.71      0.71      2264\n",
      "weighted avg       0.72      0.71      0.71      2264\n",
      "\n",
      "====  DecisionTreeClassifier  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.70      1132\n",
      "           1       0.70      0.69      0.70      1132\n",
      "\n",
      "    accuracy                           0.70      2264\n",
      "   macro avg       0.70      0.70      0.70      2264\n",
      "weighted avg       0.70      0.70      0.70      2264\n",
      "\n",
      "====  XGBClassifier  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1132\n",
      "           1       0.83      0.81      0.82      1132\n",
      "\n",
      "    accuracy                           0.82      2264\n",
      "   macro avg       0.82      0.82      0.82      2264\n",
      "weighted avg       0.82      0.82      0.82      2264\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PTT_output = baseline_model(PTT_train['content'], PTT_test['content'], \n",
    "                            PTT_train['label'], PTT_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaebe1170a994cd588cc0a3d2f8d59c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====  BernoulliNB  ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.29      0.35      4326\n",
      "           1       0.00      0.00      0.00       261\n",
      "           2       1.00      0.07      0.13      1473\n",
      "           3       0.29      0.72      0.42      7344\n",
      "           4       0.99      0.07      0.13      1526\n",
      "           5       0.99      0.19      0.31      1573\n",
      "           6       0.70      0.55      0.61     18266\n",
      "           7       1.00      0.00      0.01       835\n",
      "\n",
      "    accuracy                           0.48     35604\n",
      "   macro avg       0.68      0.24      0.24     35604\n",
      "weighted avg       0.63      0.48      0.47     35604\n",
      "\n",
      "====  MultinomialNB  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.62      0.41      4326\n",
      "           1       1.00      0.01      0.02       261\n",
      "           2       0.56      0.98      0.71      1473\n",
      "           3       0.46      0.45      0.45      7344\n",
      "           4       0.72      0.99      0.84      1526\n",
      "           5       0.54      1.00      0.70      1573\n",
      "           6       0.79      0.49      0.60     18266\n",
      "           7       0.99      0.82      0.90       835\n",
      "\n",
      "    accuracy                           0.56     35604\n",
      "   macro avg       0.67      0.67      0.58     35604\n",
      "weighted avg       0.64      0.56      0.57     35604\n",
      "\n",
      "====  SVC  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.41      0.35      4326\n",
      "           1       0.86      0.97      0.92       261\n",
      "           2       0.27      0.99      0.43      1473\n",
      "           3       0.46      0.31      0.37      7344\n",
      "           4       0.34      1.00      0.50      1526\n",
      "           5       0.42      1.00      0.59      1573\n",
      "           6       0.79      0.44      0.56     18266\n",
      "           7       0.81      0.99      0.89       835\n",
      "\n",
      "    accuracy                           0.49     35604\n",
      "   macro avg       0.53      0.76      0.58     35604\n",
      "weighted avg       0.61      0.49      0.50     35604\n",
      "\n",
      "====  LogisticRegression  ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.53      0.37      4326\n",
      "           1       1.00      0.01      0.02       261\n",
      "           2       0.38      0.98      0.54      1473\n",
      "           3       0.46      0.35      0.39      7344\n",
      "           4       0.45      0.99      0.61      1526\n",
      "           5       0.49      0.99      0.66      1573\n",
      "           6       0.77      0.46      0.58     18266\n",
      "           7       0.97      0.73      0.83       835\n",
      "\n",
      "    accuracy                           0.51     35604\n",
      "   macro avg       0.60      0.63      0.50     35604\n",
      "weighted avg       0.61      0.51      0.52     35604\n",
      "\n",
      "====  RandomForestClassifier  ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doudi\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.24      0.26      4326\n",
      "           1       0.58      0.96      0.73       261\n",
      "           2       0.28      0.98      0.44      1473\n",
      "           3       0.45      0.19      0.27      7344\n",
      "           4       0.32      0.97      0.48      1526\n",
      "           5       0.39      0.96      0.56      1573\n",
      "           6       0.70      0.53      0.61     18266\n",
      "           7       0.88      0.93      0.91       835\n",
      "\n",
      "    accuracy                           0.50     35604\n",
      "   macro avg       0.49      0.72      0.53     35604\n",
      "weighted avg       0.56      0.50      0.49     35604\n",
      "\n",
      "====  KNeighborsClassifier  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.42      0.33      4326\n",
      "           1       0.19      0.50      0.28       261\n",
      "           2       0.18      0.66      0.28      1473\n",
      "           3       0.38      0.29      0.32      7344\n",
      "           4       0.23      0.49      0.31      1526\n",
      "           5       0.23      0.59      0.33      1573\n",
      "           6       0.71      0.34      0.46     18266\n",
      "           7       0.36      0.36      0.36       835\n",
      "\n",
      "    accuracy                           0.37     35604\n",
      "   macro avg       0.32      0.46      0.33     35604\n",
      "weighted avg       0.51      0.37      0.39     35604\n",
      "\n",
      "====  DecisionTreeClassifier  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.11      0.14      4326\n",
      "           1       0.66      1.00      0.80       261\n",
      "           2       0.37      1.00      0.54      1473\n",
      "           3       0.29      0.20      0.24      7344\n",
      "           4       0.27      1.00      0.42      1526\n",
      "           5       0.25      0.99      0.40      1573\n",
      "           6       0.71      0.38      0.50     18266\n",
      "           7       0.46      1.00      0.63       835\n",
      "\n",
      "    accuracy                           0.41     35604\n",
      "   macro avg       0.40      0.71      0.46     35604\n",
      "weighted avg       0.50      0.41      0.40     35604\n",
      "\n",
      "====  XGBClassifier  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.15      0.18      4326\n",
      "           1       0.54      0.18      0.27       261\n",
      "           2       0.10      0.33      0.16      1473\n",
      "           3       0.39      0.11      0.17      7344\n",
      "           4       0.14      0.33      0.20      1526\n",
      "           5       0.21      0.27      0.24      1573\n",
      "           6       0.59      0.65      0.62     18266\n",
      "           7       0.72      0.17      0.28       835\n",
      "\n",
      "    accuracy                           0.42     35604\n",
      "   macro avg       0.36      0.27      0.26     35604\n",
      "weighted avg       0.45      0.42      0.41     35604\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RE_output = baseline_model(RE_train['concate'].values.astype('U'), RE_test['concate'].values.astype('U'), RE_train['tag_Num'], RE_test['tag_Num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                Models  Result f1 scores\n",
       " 0         Bernoulli NB          0.244797\n",
       " 1       Multinomial NB          0.578334\n",
       " 2         Svm (linear)          0.577029\n",
       " 3  Logistic Regression          0.500006\n",
       " 4        Random Forest          0.530450\n",
       " 5                  kNN          0.333972\n",
       " 6        Decision Tree          0.457719\n",
       " 7             XG Boost          0.263893,\n",
       "                 Models  Result acc scores\n",
       " 0         Bernoulli NB           0.477755\n",
       " 1       Multinomial NB           0.564515\n",
       " 2         Svm (linear)           0.494916\n",
       " 3  Logistic Regression           0.514886\n",
       " 4        Random Forest           0.496264\n",
       " 5                  kNN           0.371672\n",
       " 6        Decision Tree           0.410684\n",
       " 7             XG Boost           0.418296)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RE_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
