{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DialEval-1 DNN practice (with evaluation function)\n",
    "### Model : CNN, LSTM\n",
    "##### input round, sender pred label\n",
    "##### Edited by Weber Huang in 2020-05-28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Eval function and customizes loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "\n",
    "def normalize(pred, truth):\n",
    "    \"\"\" convert inputs to np.array and make sure\n",
    "    inputs are normalized probability distributions\n",
    "    \"\"\"\n",
    "    if len(pred) != len(truth):\n",
    "        raise ValueError(\"pred and truth have different lengths\")\n",
    "    if len(pred) == 0 or len(truth) == 0:\n",
    "        raise ValueError(\"pred or truth are empty\")\n",
    "\n",
    "    pred, truth = np.asarray(pred), np.asarray(truth)\n",
    "    if not ((pred >= 0).all() and (truth >= 0).all()):\n",
    "        raise ValueError(\"probability distribution should not be negative\")\n",
    "    pred, truth = pred / pred.sum(), truth / truth.sum()\n",
    "    return pred, truth\n",
    "\n",
    "def jensen_shannon_div(pred, truth, base=2):\n",
    "    ''' JSD: Jensen-Shannon Divergence\n",
    "    '''\n",
    "    pred, truth = normalize(pred, truth)\n",
    "    m = 1. / 2 * (pred + truth)\n",
    "    return (stats.entropy(pred, m, base=base)\n",
    "            + stats.entropy(truth, m, base=base)) / 2.\n",
    "\n",
    "def root_normalized_squared_error(pred, truth):\n",
    "    \"\"\" RNSS: Root Normalised Sum of Squares\n",
    "    \"\"\"\n",
    "\n",
    "    def squared_error(pred, truth):\n",
    "        return ((pred - truth) ** 2).sum()\n",
    "\n",
    "    pred, truth = normalize(pred, truth)\n",
    "    return np.sqrt(squared_error(pred, truth) / 2)\n",
    "\n",
    "def jsd_custom_loss(y_true, y_pred):\n",
    "            \n",
    "    # calculate loss, using y_pred\n",
    "    ''' JSD: Jensen-Shannon Divergence\n",
    "    '''\n",
    "#     y_pred, y_true = normalize(y_pred, y_true)\n",
    "    m = 1. / 2 * (y_pred + y_true)\n",
    "    # loss = (stats.entropy(y_pred, m, base=2) + stats.entropy(y_true, m, base=2)) / 2.\n",
    "    # tf.keras.losses.KLD()\n",
    "    loss = (tf.keras.losses.KLD(y_pred, m) + tf.keras.losses.KLD(y_true, m)) / 2.\n",
    "    return loss\n",
    "  \n",
    "# model.compile(loss=jsd_custom_loss, optimizer='adam')\n",
    "\n",
    "def rnss_custom_loss(y_true, y_pred):\n",
    "            \n",
    "    # calculate loss, using y_pred\n",
    "    \"\"\" RNSS: Root Normalised Sum of Squares\n",
    "    \"\"\"\n",
    "\n",
    "    def squared_error(y_pred, y_true):\n",
    "        return ((y_pred - y_true) ** 2).sum()\n",
    "\n",
    "#     y_pred, y_true = normalize(y_pred, y_true)\n",
    "    loss = np.sqrt(squared_error(y_pred, y_true) / 2)\n",
    "    \n",
    "    return loss\n",
    "  \n",
    "# model.compile(loss=custom_loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. input dataset and modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('C:/Users/doudi/OneDrive/Documents/ntcir15/Dataset/DialEval-1')\n",
    "df = pd.read_excel(r'./200514_dev+train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>round</th>\n",
       "      <th>sender</th>\n",
       "      <th>texts</th>\n",
       "      <th>max_label</th>\n",
       "      <th>round_label</th>\n",
       "      <th>CNUG</th>\n",
       "      <th>CNUG*</th>\n",
       "      <th>CNUG0</th>\n",
       "      <th>CNaN</th>\n",
       "      <th>HNUG</th>\n",
       "      <th>HNUG*</th>\n",
       "      <th>HNaN</th>\n",
       "      <th>sender_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>1</td>\n",
       "      <td>customer</td>\n",
       "      <td>内涵 段子 联通 皮 点赞 中国联通 中国联通 客服 掌上 营业厅 内涵 段子 话题 封 郑...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>2</td>\n",
       "      <td>helpdesk</td>\n",
       "      <td>u</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>3</td>\n",
       "      <td>customer</td>\n",
       "      <td>夸夸</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>4</td>\n",
       "      <td>helpdesk</td>\n",
       "      <td>*</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4121001149457180</td>\n",
       "      <td>1</td>\n",
       "      <td>customer</td>\n",
       "      <td>距离 反映 问题 已经 一个 星期 花粉 助手 D 荣耀 honor 荣耀 手机 华为 终端...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  round    sender  \\\n",
       "0  4227729258237820      1  customer   \n",
       "1  4227729258237820      2  helpdesk   \n",
       "2  4227729258237820      3  customer   \n",
       "3  4227729258237820      4  helpdesk   \n",
       "4  4121001149457180      1  customer   \n",
       "\n",
       "                                               texts  max_label  round_label  \\\n",
       "0  内涵 段子 联通 皮 点赞 中国联通 中国联通 客服 掌上 营业厅 内涵 段子 话题 封 郑...          3            2   \n",
       "1                                                  u          6            4   \n",
       "2                                                 夸夸          3            0   \n",
       "3                                                  *          6            4   \n",
       "4  距离 反映 问题 已经 一个 星期 花粉 助手 D 荣耀 honor 荣耀 手机 华为 终端...          2            2   \n",
       "\n",
       "       CNUG  CNUG*     CNUG0      CNaN      HNUG  HNUG*      HNaN  sender_num  \n",
       "0  0.052632    0.0  0.157895  0.789474  0.000000    0.0  0.000000           0  \n",
       "1  0.000000    0.0  0.000000  0.000000  0.157895    0.0  0.842105           1  \n",
       "2  0.157895    0.0  0.000000  0.842105  0.000000    0.0  0.000000           0  \n",
       "3  0.000000    0.0  0.000000  0.000000  0.157895    0.0  0.842105           1  \n",
       "4  0.052632    0.0  0.789474  0.157895  0.000000    0.0  0.000000           0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = []\n",
    "for i in df['sender']:\n",
    "    if i == 'customer':\n",
    "        tmp.append(0)\n",
    "    else:\n",
    "        tmp.append(1)\n",
    "df['sender_num'] = tmp\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17155, 14)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import Convolution1D, Flatten, Dropout, MaxPool1D, GlobalAveragePooling1D\n",
    "from keras.layers import concatenate\n",
    "from keras import initializers\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "# from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "dev = df[0:1754]\n",
    "train = df[1755:]\n",
    "\n",
    "X_train = train.filter(['round','sender_num','texts'])\n",
    "X_test = dev.filter(['round','sender_num','texts'])\n",
    "y_train = train.filter(['CNUG','CNUG*','CNUG0','CNaN','HNUG','HNUG*','HNaN'])\n",
    "y_test = dev.filter(['CNUG','CNUG*','CNUG0','CNaN','HNUG','HNUG*','HNaN'])\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. DNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(X_train, X_test, y_train, y_test, loss='categorical_crossentropy'):\n",
    "    \n",
    "    X1_train = X_train['texts']\n",
    "#     X1_train = X_train[:,[-1]]\n",
    "    X1_train = [str (item) for item in X1_train]\n",
    "    \n",
    "    X1_test = X_test['texts']\n",
    "#     X1_test = X_test[:,[-1]]\n",
    "    X1_test = [str (item) for item in X1_test]\n",
    "\n",
    "    X2_train = X_train[['round','sender_num']].values\n",
    "#     X2_train = X_train[:,0:7]\n",
    "    X2_test = X_test[['round','sender_num']].values\n",
    "#     X2_test = X_test[:,0:7]\n",
    "    \n",
    "    token = Tokenizer(num_words = 20000)\n",
    "    token.fit_on_texts(X1_train)\n",
    "    vocab = token.word_index\n",
    "    print(token.document_count)\n",
    "\n",
    "    x_train_seq = token.texts_to_sequences(X1_train)\n",
    "    x_test_seq = token.texts_to_sequences(X1_test)\n",
    "    X1_train = sequence.pad_sequences(x_train_seq, maxlen = 150)\n",
    "    X1_test = sequence.pad_sequences(x_test_seq, maxlen = 150)\n",
    "\n",
    "#     y_one_train = np_utils.to_categorical(y_train)\n",
    "#     y_one_test = np_utils.to_categorical(y_test)\n",
    "     \n",
    "    num_labels = 7\n",
    "    main_input = Input(shape=(150,), dtype='float64')\n",
    "\n",
    "    sub_input = Input(shape=(2,))\n",
    "    \n",
    "    # pre-train embeddings\n",
    "    # embedder = Embedding(len(vocab) + 1, 300, input_length = 20, weights = [embedding_matrix], trainable = False)\n",
    "    # embed = embedder(main_input)\n",
    "    embed = Embedding(len(vocab)+1, 300, input_length=150)(main_input)\n",
    "    # filter size, region size\n",
    "    cnn = Convolution1D(2, 2, padding='same', strides = 1, activation='relu')(embed)\n",
    "    cnn = MaxPool1D(pool_size=4)(cnn)\n",
    "    flat = Flatten()(cnn)\n",
    "    drop = Dropout(0.2)(flat)\n",
    "    # main_output = Dense(num_labels, activation='sigmoid')(drop)\n",
    "\n",
    "\n",
    "    dense_1 = Dense(units=256,activation='relu')(sub_input)\n",
    "    drop_1 = Dropout(0.35)(dense_1)\n",
    "    dense_2 = Dense(units=128,activation='relu')(drop_1)\n",
    "    # sub_output = Dense(units=2,activation='sigmoid')(dense_2)\n",
    "\n",
    "    merge = concatenate([drop, dense_2])\n",
    "    dense_3 = Dense(units=10, activation='relu')(merge)\n",
    "    output = Dense(units=7, activation='softmax')(dense_3)\n",
    "\n",
    "    model = Model(inputs=[main_input, sub_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    # checkpoint\n",
    "    # filepath=\"C:/Users/doudi/OneDrive/Documents/TMU-GIDS/Lab/Competition/AI cup 2019/weights.best.hdf5\"\n",
    "    # checkpoint= ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    train_history = model.fit(x=[X1_train, X2_train], y=y_train, epochs=10, \n",
    "                              batch_size=32, verbose=1, validation_split=0.2)\n",
    "\n",
    "    score = model.evaluate(x=[X1_test, X2_test], y=y_test, verbose=1)\n",
    "\n",
    "    print(\"Test Score:\", score[0])\n",
    "    print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "    pre_probability = model.predict(x=[X1_test, X2_test])\n",
    "    predicted = pre_probability.argmax(axis=-1)\n",
    "    \n",
    "    return train_history, pre_probability\n",
    "    '''\n",
    "    from sklearn import metrics\n",
    "    print(\"Classification report for classifier:\\n%s\\n\"\n",
    "          % ( metrics.classification_report(y_test, predicted)))\n",
    "\n",
    "    print(\"f1_score :\\n%s\\n\" % ( metrics.f1_score(y_test, predicted, average='macro')))\n",
    "    print(\"acc_score :\\n%s\\n\" % ( metrics.accuracy_score(y_test, predicted)))\n",
    "    '''\n",
    "\n",
    "def lstm(X_train, X_test, y_train, y_test, loss='categorical_crossentropy'):\n",
    "    X1_train = X_train['texts']\n",
    "#     X1_train = X_train[:,[-1]]\n",
    "    X1_train = [str (item) for item in X1_train]\n",
    "    \n",
    "    X1_test = X_test['texts']\n",
    "#     X1_test = X_test[:,[-1]]\n",
    "    X1_test = [str (item) for item in X1_test]\n",
    "\n",
    "    X2_train = X_train[['round','sender_num']].values\n",
    "#     X2_train = X_train[:,0:7]\n",
    "    X2_test = X_test[['round','sender_num']].values\n",
    "#     X2_test = X_test[:,0:7]\n",
    "    \n",
    "    token = Tokenizer(num_words = 20000)\n",
    "    token.fit_on_texts(X1_train)\n",
    "    print(token.document_count)\n",
    "\n",
    "    x_train_seq = token.texts_to_sequences(X1_train)\n",
    "    x_test_seq = token.texts_to_sequences(X1_test)\n",
    "    X1_train = sequence.pad_sequences(x_train_seq, maxlen = 150)\n",
    "    X1_test = sequence.pad_sequences(x_test_seq, maxlen = 150)\n",
    "\n",
    "#     y_one_train = np_utils.to_categorical(y_train)\n",
    "#     y_one_test = np_utils.to_categorical(y_test)\n",
    "     \n",
    "    main_input = Input(shape=(150,), dtype='float64')\n",
    "    sub_input = Input(shape=(2,))\n",
    "    \n",
    "    embed = Embedding(output_dim=32,input_dim=20000,input_length=150)(main_input)\n",
    "    dropout_1 = Dropout(0.35)(embed)\n",
    "    lst = LSTM(units=16)(dropout_1)\n",
    "    dense_1 = Dense(units=256,activation='relu')(lst)\n",
    "    dropout_2 = Dropout(0.35)(dense_1)\n",
    "    dense_2 = Dense(units=128,activation='relu')(dropout_2)\n",
    "    dense_3 = Dense(units=7,activation='softmax')(dense_2)\n",
    "\n",
    "\n",
    "    dense_4 = Dense(units=256,activation='relu')(sub_input)\n",
    "    dropout_3 = Dropout(0.35)(dense_4)\n",
    "    dense_5 = Dense(units=128,activation='relu')(dropout_3)\n",
    "    # sub_output = Dense(units=2,activation='sigmoid')(dense_2)\n",
    "\n",
    "    merge = concatenate([dense_3, dense_5])\n",
    "    dense_6 = Dense(units=10, activation='relu')(merge)\n",
    "    output = Dense(units=7, activation='softmax')(dense_6)\n",
    "\n",
    "    model = Model(inputs=[main_input, sub_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    # checkpoint\n",
    "    # filepath=\"C:/Users/doudi/OneDrive/Documents/TMU-GIDS/Lab/Competition/AI cup 2019/weights.best.hdf5\"\n",
    "    # checkpoint= ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    train_history = model.fit(x=[X1_train, X2_train], y=y_train, epochs=10, \n",
    "                              batch_size=128, verbose=1, validation_split=0.2)\n",
    "\n",
    "    score = model.evaluate(x=[X1_test, X2_test], y=y_test, verbose=1)\n",
    "\n",
    "    print(\"Test Score:\", score[0])\n",
    "    print(\"Test Accuracy:\", score[1])\n",
    "\n",
    "    pre_probability = model.predict(x=[X1_test, X2_test])\n",
    "    predicted = pre_probability.argmax(axis=-1)\n",
    "    \n",
    "    return train_history, pre_probability\n",
    "    '''\n",
    "    from sklearn import metrics\n",
    "    print(\"Classification report for classifier:\\n%s\\n\"\n",
    "          % ( metrics.classification_report(y_test, predicted)))\n",
    "\n",
    "    print(\"f1_score :\\n%s\\n\" % ( metrics.f1_score(y_test, predicted, average='macro')))\n",
    "    print(\"acc_score :\\n%s\\n\" % ( metrics.accuracy_score(y_test, predicted)))\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_folds = 3\\nmodel_history = []\\nfor i in tqdm(range(n_folds)):\\n    print(\"Training on Fold: \",i+1)\\n    from sklearn.model_selection import train_test_split\\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, \\n                                                        random_state = np.random.randint(1,1000, 1)[0])\\n                                               \\n    \\n    model_history.append(CNN(X_train, X_test, y_train, y_test))\\n    print(\"=======\"*12, end=\"\\n\\n\\n\")\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "'''\n",
    "n_folds = 3\n",
    "model_history = []\n",
    "for i in tqdm(range(n_folds)):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, \n",
    "                                                        random_state = np.random.randint(1,1000, 1)[0])\n",
    "                                               \n",
    "    \n",
    "    model_history.append(CNN(X_train, X_test, y_train, y_test))\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15400\n",
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_33 (InputLayer)           (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 150, 300)     6533100     input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 150, 2)       1202        embedding_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 37, 2)        0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 256)          768         input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 74)           0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 256)          0           dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 74)           0           flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 128)          32896       dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 202)          0           dropout_34[0][0]                 \n",
      "                                                                 dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 10)           2030        concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 7)            77          dense_70[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,570,073\n",
      "Trainable params: 6,570,073\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 12320 samples, validate on 3080 samples\n",
      "Epoch 1/10\n",
      "12320/12320 [==============================] - 5s 428us/step - loss: 1.0085 - accuracy: 0.7599 - val_loss: 0.8154 - val_accuracy: 0.8510\n",
      "Epoch 2/10\n",
      "12320/12320 [==============================] - 5s 386us/step - loss: 0.8200 - accuracy: 0.8338 - val_loss: 0.8058 - val_accuracy: 0.8484\n",
      "Epoch 3/10\n",
      "12320/12320 [==============================] - 5s 390us/step - loss: 0.7985 - accuracy: 0.8390 - val_loss: 0.8000 - val_accuracy: 0.8523\n",
      "Epoch 4/10\n",
      "12320/12320 [==============================] - 5s 387us/step - loss: 0.7865 - accuracy: 0.8429 - val_loss: 0.7951 - val_accuracy: 0.8656\n",
      "Epoch 5/10\n",
      "12320/12320 [==============================] - 5s 387us/step - loss: 0.7784 - accuracy: 0.8423 - val_loss: 0.7932 - val_accuracy: 0.8536\n",
      "Epoch 6/10\n",
      "12320/12320 [==============================] - 5s 385us/step - loss: 0.7728 - accuracy: 0.8461 - val_loss: 0.7945 - val_accuracy: 0.8601\n",
      "Epoch 7/10\n",
      "12320/12320 [==============================] - 5s 387us/step - loss: 0.7688 - accuracy: 0.8515 - val_loss: 0.7988 - val_accuracy: 0.8591\n",
      "Epoch 8/10\n",
      "12320/12320 [==============================] - 5s 387us/step - loss: 0.7657 - accuracy: 0.8530 - val_loss: 0.7962 - val_accuracy: 0.8659\n",
      "Epoch 9/10\n",
      "12320/12320 [==============================] - 5s 387us/step - loss: 0.7626 - accuracy: 0.8539 - val_loss: 0.7961 - val_accuracy: 0.8558\n",
      "Epoch 10/10\n",
      "12320/12320 [==============================] - 5s 388us/step - loss: 0.7617 - accuracy: 0.8536 - val_loss: 0.7993 - val_accuracy: 0.8623\n",
      "1754/1754 [==============================] - 0s 70us/step\n",
      "Test Score: 0.7903723472744193\n",
      "Test Accuracy: 0.8563283681869507\n"
     ]
    }
   ],
   "source": [
    "# use categorical_crossentropy as loss function\n",
    "train_history , pred = CNN(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15400\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_35 (InputLayer)           (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 150, 32)      640000      input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 150, 32)      0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 16)           3136        dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 256)          4352        lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 256)          0           dense_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 256)          768         input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 128)          32896       dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 256)          0           dense_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 7)            903         dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 128)          32896       dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 135)          0           dense_74[0][0]                   \n",
      "                                                                 dense_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 10)           1360        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 7)            77          dense_77[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 716,388\n",
      "Trainable params: 716,388\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 12320 samples, validate on 3080 samples\n",
      "Epoch 1/10\n",
      "12320/12320 [==============================] - 13s 1ms/step - loss: 1.4871 - accuracy: 0.6254 - val_loss: 1.1138 - val_accuracy: 0.8484\n",
      "Epoch 2/10\n",
      "12320/12320 [==============================] - 12s 993us/step - loss: 0.9810 - accuracy: 0.8173 - val_loss: 0.8548 - val_accuracy: 0.8513\n",
      "Epoch 3/10\n",
      "12320/12320 [==============================] - 12s 969us/step - loss: 0.8494 - accuracy: 0.8267 - val_loss: 0.8217 - val_accuracy: 0.8536\n",
      "Epoch 4/10\n",
      "12320/12320 [==============================] - 12s 972us/step - loss: 0.8241 - accuracy: 0.8442 - val_loss: 0.8122 - val_accuracy: 0.8808\n",
      "Epoch 5/10\n",
      "12320/12320 [==============================] - 12s 987us/step - loss: 0.8082 - accuracy: 0.8567 - val_loss: 0.8087 - val_accuracy: 0.8487\n",
      "Epoch 6/10\n",
      "12320/12320 [==============================] - 12s 964us/step - loss: 0.7934 - accuracy: 0.8662 - val_loss: 0.7992 - val_accuracy: 0.8594\n",
      "Epoch 7/10\n",
      "12320/12320 [==============================] - 12s 969us/step - loss: 0.7823 - accuracy: 0.8715 - val_loss: 0.7900 - val_accuracy: 0.8695\n",
      "Epoch 8/10\n",
      "12320/12320 [==============================] - 12s 970us/step - loss: 0.7714 - accuracy: 0.8747 - val_loss: 0.7923 - val_accuracy: 0.8812\n",
      "Epoch 9/10\n",
      "12320/12320 [==============================] - 12s 961us/step - loss: 0.7625 - accuracy: 0.8768 - val_loss: 0.7893 - val_accuracy: 0.8630\n",
      "Epoch 10/10\n",
      "12320/12320 [==============================] - 12s 963us/step - loss: 0.7553 - accuracy: 0.8744 - val_loss: 0.7868 - val_accuracy: 0.8682\n",
      "1754/1754 [==============================] - 3s 2ms/step\n",
      "Test Score: 0.774211578929166\n",
      "Test Accuracy: 0.8472064137458801\n"
     ]
    }
   ],
   "source": [
    "# use categorical_crossentropy as loss function\n",
    "train_history_ls , pred_ls = lstm(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15400\n",
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_37 (InputLayer)           (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 150, 300)     6533100     input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 150, 2)       1202        embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_38 (InputLayer)           (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 37, 2)        0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 256)          768         input_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 74)           0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 256)          0           dense_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 74)           0           flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 128)          32896       dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 202)          0           dropout_39[0][0]                 \n",
      "                                                                 dense_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_81 (Dense)                (None, 10)           2030        concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 7)            77          dense_81[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,570,073\n",
      "Trainable params: 6,570,073\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 12320 samples, validate on 3080 samples\n",
      "Epoch 1/10\n",
      "12320/12320 [==============================] - 6s 449us/step - loss: 0.1016 - accuracy: 0.7751 - val_loss: 0.0592 - val_accuracy: 0.8513\n",
      "Epoch 2/10\n",
      "12320/12320 [==============================] - 5s 398us/step - loss: 0.0533 - accuracy: 0.8291 - val_loss: 0.0422 - val_accuracy: 0.8487\n",
      "Epoch 3/10\n",
      "12320/12320 [==============================] - 5s 398us/step - loss: 0.0414 - accuracy: 0.8366 - val_loss: 0.0382 - val_accuracy: 0.8542\n",
      "Epoch 4/10\n",
      "12320/12320 [==============================] - 5s 399us/step - loss: 0.0376 - accuracy: 0.8343 - val_loss: 0.0367 - val_accuracy: 0.8545\n",
      "Epoch 5/10\n",
      "12320/12320 [==============================] - 5s 389us/step - loss: 0.0360 - accuracy: 0.8387 - val_loss: 0.0367 - val_accuracy: 0.8545\n",
      "Epoch 6/10\n",
      "12320/12320 [==============================] - 5s 397us/step - loss: 0.0346 - accuracy: 0.8426 - val_loss: 0.0364 - val_accuracy: 0.8555\n",
      "Epoch 7/10\n",
      "12320/12320 [==============================] - 5s 395us/step - loss: 0.0338 - accuracy: 0.8433 - val_loss: 0.0364 - val_accuracy: 0.8610\n",
      "Epoch 8/10\n",
      "12320/12320 [==============================] - 5s 395us/step - loss: 0.0326 - accuracy: 0.8456 - val_loss: 0.0368 - val_accuracy: 0.8497\n",
      "Epoch 9/10\n",
      "12320/12320 [==============================] - 5s 395us/step - loss: 0.0315 - accuracy: 0.8489 - val_loss: 0.0355 - val_accuracy: 0.8627\n",
      "Epoch 10/10\n",
      "12320/12320 [==============================] - 5s 395us/step - loss: 0.0308 - accuracy: 0.8502 - val_loss: 0.0364 - val_accuracy: 0.8555\n",
      "1754/1754 [==============================] - 0s 69us/step\n",
      "Test Score: 0.03548093564477043\n",
      "Test Accuracy: 0.8443557620048523\n"
     ]
    }
   ],
   "source": [
    "# use jsd as loss function\n",
    "train_history_jsd , pred_jsd = CNN(X_train, X_test, y_train, y_test, loss = jsd_custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15400\n",
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_39 (InputLayer)           (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 150, 32)      640000      input_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 150, 32)      0           embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 16)           3136        dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 256)          4352        lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_40 (InputLayer)           (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 256)          0           dense_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 256)          768         input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 128)          32896       dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 256)          0           dense_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 7)            903         dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 128)          32896       dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 135)          0           dense_85[0][0]                   \n",
      "                                                                 dense_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 10)           1360        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 7)            77          dense_88[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 716,388\n",
      "Trainable params: 716,388\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 12320 samples, validate on 3080 samples\n",
      "Epoch 1/10\n",
      "12320/12320 [==============================] - 13s 1ms/step - loss: 0.1958 - accuracy: 0.5488 - val_loss: 0.0623 - val_accuracy: 0.8513\n",
      "Epoch 2/10\n",
      "12320/12320 [==============================] - 12s 964us/step - loss: 0.0581 - accuracy: 0.8231 - val_loss: 0.0477 - val_accuracy: 0.8513\n",
      "Epoch 3/10\n",
      "12320/12320 [==============================] - 12s 961us/step - loss: 0.0490 - accuracy: 0.8314 - val_loss: 0.0445 - val_accuracy: 0.8383\n",
      "Epoch 4/10\n",
      "12320/12320 [==============================] - 12s 964us/step - loss: 0.0453 - accuracy: 0.8300 - val_loss: 0.0420 - val_accuracy: 0.8516\n",
      "Epoch 5/10\n",
      "12320/12320 [==============================] - 12s 966us/step - loss: 0.0430 - accuracy: 0.8331 - val_loss: 0.0408 - val_accuracy: 0.8516\n",
      "Epoch 6/10\n",
      "12320/12320 [==============================] - 12s 967us/step - loss: 0.0407 - accuracy: 0.8352 - val_loss: 0.0407 - val_accuracy: 0.8513\n",
      "Epoch 7/10\n",
      "12320/12320 [==============================] - 12s 968us/step - loss: 0.0389 - accuracy: 0.8380 - val_loss: 0.0400 - val_accuracy: 0.8731\n",
      "Epoch 8/10\n",
      "12320/12320 [==============================] - 12s 962us/step - loss: 0.0369 - accuracy: 0.8442 - val_loss: 0.0389 - val_accuracy: 0.8649\n",
      "Epoch 9/10\n",
      "12320/12320 [==============================] - 12s 956us/step - loss: 0.0356 - accuracy: 0.8489 - val_loss: 0.0380 - val_accuracy: 0.8724\n",
      "Epoch 10/10\n",
      "12320/12320 [==============================] - 12s 959us/step - loss: 0.0343 - accuracy: 0.8483 - val_loss: 0.0381 - val_accuracy: 0.8656\n",
      "1754/1754 [==============================] - 3s 2ms/step\n",
      "Test Score: 0.03716902745337552\n",
      "Test Accuracy: 0.8449258804321289\n"
     ]
    }
   ],
   "source": [
    "# use jsd as loss function\n",
    "train_history_ls_jsd , pred_ls_jsd = lstm(X_train, X_test, y_train, y_test, loss = jsd_custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15400\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-6ffbff0e478b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# use rnss as loss function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_history_rnss\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mpred_rnss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnss_custom_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-82-5eb36889da1a>\u001b[0m in \u001b[0;36mCNN\u001b[1;34m(X_train, X_test, y_train, y_test, loss)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmain_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m#                   loss_weight_2 * output_2_loss_fn(...) +\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;31m#                   layer losses.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_total_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;31m# Functions for train, test and predict will\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_prepare_total_loss\u001b[1;34m(self, masks)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                     output_loss = loss_fn(\n\u001b[1;32m--> 692\u001b[1;33m                         y_true, y_pred, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\losses.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mscope_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'lambda'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'<lambda>'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscope_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m             return losses_utils.compute_weighted_loss(\n\u001b[0;32m     73\u001b[0m                 losses, sample_weight, reduction=self.reduction)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\losses.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mLoss\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \"\"\"\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-89f0b9163a1b>\u001b[0m in \u001b[0;36mrnss_custom_loss\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;31m#     y_pred, y_true = normalize(y_pred, y_true)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msquared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-89f0b9163a1b>\u001b[0m in \u001b[0;36msquared_error\u001b[1;34m(y_pred, y_true)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msquared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;31m#     y_pred, y_true = normalize(y_pred, y_true)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "# use rnss as loss function\n",
    "# train_history_rnss , pred_rnss = CNN(X_train, X_test, y_train, y_test, loss = rnss_custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use rnss as loss function\n",
    "# train_history_ls_rnss , pred_ls_rnss = lstm(X_train, X_test, y_train, y_test, loss = rnss_custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = np.array(y_test)\n",
    "def calculate_divergence(true, pred):\n",
    "    tmp = 0\n",
    "    for i in range(len(true)):\n",
    "        tmp = tmp + jensen_shannon_div(pred[i], true[i])\n",
    "    \n",
    "    print('mean jsd :', tmp/len(true))\n",
    "    \n",
    "    tmp = 0\n",
    "    for i in range(len(true)):\n",
    "        tmp = tmp + root_normalized_squared_error(pred[i], true[i])\n",
    "    \n",
    "    print('mean rnss :', tmp/len(true))\n",
    "    \n",
    "#         print('---sentence{0}---'.format(i))\n",
    "#         print('jsd :', jensen_shannon_div(pred[i], true[i]))\n",
    "#         print('rnss :', root_normalized_squared_error(pred[i], true[i]))\n",
    "\n",
    "# print('--- textCNN ---', '\\n')\n",
    "# calculate_divergence(true, pred)\n",
    "\n",
    "# print('--- LSTM ---', '\\n')\n",
    "# calculate_divergence(true, pred_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== categorical_crossentropy === \n",
      "\n",
      "---textCNN---\n",
      "mean jsd : 0.05153927563537783\n",
      "mean rnss : 0.14659849085911045\n",
      "---LSTM---\n",
      "mean jsd : 0.04705732779576456\n",
      "mean rnss : 0.13304897800666488\n",
      "\n",
      " === loss_jsd === \n",
      "\n",
      "---textCNN---\n",
      "mean jsd : 0.05118964231857076\n",
      "mean rnss : 0.14899200261727294\n",
      "---LSTM---\n",
      "mean jsd : 0.05362496832814412\n",
      "mean rnss : 0.14883823918886524\n"
     ]
    }
   ],
   "source": [
    "print('=== categorical_crossentropy ===', '\\n')\n",
    "print('---textCNN---')\n",
    "calculate_divergence(true, pred)\n",
    "print('---LSTM---')\n",
    "calculate_divergence(true, pred_ls)\n",
    "print('\\n', '=== loss_jsd ===', '\\n')\n",
    "print('---textCNN---')\n",
    "calculate_divergence(true, pred_jsd)\n",
    "print('---LSTM---')\n",
    "calculate_divergence(true, pred_ls_jsd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
