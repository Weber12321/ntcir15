{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "# from sklearn import cross_validation\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "dataset = pd.read_excel(r'./200416_label0_dataset_sentence.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>round</th>\n",
       "      <th>sender</th>\n",
       "      <th>texts</th>\n",
       "      <th>max_label</th>\n",
       "      <th>round_label</th>\n",
       "      <th>labels</th>\n",
       "      <th>sender_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>1</td>\n",
       "      <td>customer</td>\n",
       "      <td>内涵 段子 联通 皮 点赞 中国联通 中国联通 客服 掌上 营业厅 内涵 段子 话题 封 郑...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>2</td>\n",
       "      <td>helpdesk</td>\n",
       "      <td>u</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>3</td>\n",
       "      <td>customer</td>\n",
       "      <td>夸夸</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4227729258237820</td>\n",
       "      <td>4</td>\n",
       "      <td>helpdesk</td>\n",
       "      <td>*</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4121001149457180</td>\n",
       "      <td>1</td>\n",
       "      <td>customer</td>\n",
       "      <td>距离 反映 问题 已经 一个 星期 花粉 助手 D 荣耀 honor 荣耀 手机 华为 终端...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  round    sender  \\\n",
       "0  4227729258237820      1  customer   \n",
       "1  4227729258237820      2  helpdesk   \n",
       "2  4227729258237820      3  customer   \n",
       "3  4227729258237820      4  helpdesk   \n",
       "4  4121001149457180      1  customer   \n",
       "\n",
       "                                               texts  max_label  round_label  \\\n",
       "0  内涵 段子 联通 皮 点赞 中国联通 中国联通 客服 掌上 营业厅 内涵 段子 话题 封 郑...          3            2   \n",
       "1                                                  u          6            4   \n",
       "2                                                 夸夸          3            0   \n",
       "3                                                  *          6            4   \n",
       "4  距离 反映 问题 已经 一个 星期 花粉 助手 D 荣耀 honor 荣耀 手机 华为 终端...          2            2   \n",
       "\n",
       "   labels  sender_num  \n",
       "0       1           0  \n",
       "1       0           1  \n",
       "2       1           0  \n",
       "3       0           1  \n",
       "4       1           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = []\n",
    "for i in dataset['sender']:\n",
    "    if i == 'customer':\n",
    "        tmp.append(0)\n",
    "    else:\n",
    "        tmp.append(1)\n",
    "dataset['sender_num'] = tmp\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(dataset[\"texts\"])\n",
    "max_label = list(dataset[\"max_label\"])\n",
    "Round = list(dataset[\"round\"])\n",
    "sender_num = list(dataset[\"sender_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train / dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(texts,max_label,sender_num,Round):\n",
    "    texts = [str (item) for item in texts]\n",
    "    x_train1 = tfidf_vectorizer.fit_transform(texts).toarray()\n",
    "#     x_test = tfidf_vectorizer.transform(x_test).toarray()\n",
    "    svd = TruncatedSVD(n_components=400).fit(x_train1)\n",
    "    reduced = svd.transform(x_train1)\n",
    "    total = reduced.tolist()\n",
    "    for item in range(len(total)):\n",
    "        total[item] = np.append(total[item], sender_num[item])\n",
    "    for item in range(len(total)):\n",
    "        total[item] = np.append(total[item], Round[item])\n",
    "        \n",
    "    total = np.array(total)\n",
    "    max_label = np.array(max_label)    \n",
    "        \n",
    "    x_train=total[1755:]\n",
    "    x_test=total[0:1755]\n",
    "    y_train=max_label[1755:]\n",
    "    y_test=max_label[0:1755]    \n",
    "    \n",
    "    Models = ['Bernoulli NB','Svm (linear)','Logistic Regression',\n",
    "              'Random Forest','kNN','Decision Tree']\n",
    "    function = [BernoulliNB(),svm.SVC(kernel=\"linear\"),LogisticRegression(),\n",
    "              RandomForestClassifier(),KNeighborsClassifier(),DecisionTreeClassifier()]\n",
    "    perform_f1 = []\n",
    "    perform_acc = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(len(function))):\n",
    "        model = function[i]\n",
    "#         performance = cross_val_score(model, tfidf_vectorizer.fit_transform(texts), labels, cv=10, scoring'accuracy')\n",
    "        \n",
    "        func = str(function[i])\n",
    "        print(\"==== \", func[0:func.index('(')], \" ====\")\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        model.score(x_test, y_test)\n",
    "        e = y_test\n",
    "        p = model.predict(x_test)\n",
    "        print(metrics.classification_report(e,p))\n",
    "        perform_f1.append(metrics.f1_score(e,p,average='macro'))\n",
    "        perform_acc.append(metrics.accuracy_score(e,p))\n",
    "        \n",
    "    result_f1_table = pd.DataFrame({\"Models\":Models,\"Result f1 scores\":perform_f1})\n",
    "    result_acc_table = pd.DataFrame({\"Models\":Models,\"Result acc scores\":perform_acc})\n",
    "    return result_f1_table, result_acc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5da7b83c47409dafcc34c6c29274e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====  BernoulliNB  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.77      0.72       477\n",
      "           1       0.30      0.43      0.36        23\n",
      "           2       0.71      0.69      0.70       374\n",
      "           3       0.11      0.01      0.02       101\n",
      "           4       0.88      0.91      0.89       662\n",
      "           5       0.15      0.30      0.20        33\n",
      "           6       0.38      0.29      0.33        85\n",
      "\n",
      "    accuracy                           0.72      1755\n",
      "   macro avg       0.46      0.49      0.46      1755\n",
      "weighted avg       0.70      0.72      0.71      1755\n",
      "\n",
      "====  SVC  ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.89       477\n",
      "           1       0.50      0.04      0.08        23\n",
      "           2       0.95      0.99      0.97       374\n",
      "           3       0.20      0.01      0.02       101\n",
      "           4       0.87      1.00      0.93       662\n",
      "           5       0.00      0.00      0.00        33\n",
      "           6       0.94      0.20      0.33        85\n",
      "\n",
      "    accuracy                           0.87      1755\n",
      "   macro avg       0.61      0.46      0.46      1755\n",
      "weighted avg       0.82      0.87      0.82      1755\n",
      "\n",
      "====  LogisticRegression  ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89       477\n",
      "           1       0.33      0.26      0.29        23\n",
      "           2       0.95      0.99      0.97       374\n",
      "           3       0.40      0.04      0.07       101\n",
      "           4       0.88      0.99      0.93       662\n",
      "           5       0.25      0.03      0.05        33\n",
      "           6       0.80      0.28      0.42        85\n",
      "\n",
      "    accuracy                           0.87      1755\n",
      "   macro avg       0.63      0.51      0.52      1755\n",
      "weighted avg       0.83      0.87      0.83      1755\n",
      "\n",
      "====  RandomForestClassifier  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89       477\n",
      "           1       0.29      0.09      0.13        23\n",
      "           2       0.95      0.99      0.97       374\n",
      "           3       0.33      0.05      0.09       101\n",
      "           4       0.88      0.99      0.94       662\n",
      "           5       0.50      0.03      0.06        33\n",
      "           6       0.92      0.39      0.55        85\n",
      "\n",
      "    accuracy                           0.87      1755\n",
      "   macro avg       0.67      0.50      0.52      1755\n",
      "weighted avg       0.84      0.87      0.84      1755\n",
      "\n",
      "====  KNeighborsClassifier  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       477\n",
      "           1       0.50      0.17      0.26        23\n",
      "           2       0.95      0.94      0.95       374\n",
      "           3       0.26      0.22      0.24       101\n",
      "           4       0.92      0.78      0.84       662\n",
      "           5       0.30      0.09      0.14        33\n",
      "           6       0.29      0.71      0.41        85\n",
      "\n",
      "    accuracy                           0.79      1755\n",
      "   macro avg       0.58      0.55      0.53      1755\n",
      "weighted avg       0.82      0.79      0.80      1755\n",
      "\n",
      "====  DecisionTreeClassifier  ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84       477\n",
      "           1       0.14      0.22      0.17        23\n",
      "           2       0.96      0.95      0.96       374\n",
      "           3       0.22      0.19      0.20       101\n",
      "           4       0.89      0.89      0.89       662\n",
      "           5       0.09      0.09      0.09        33\n",
      "           6       0.47      0.49      0.48        85\n",
      "\n",
      "    accuracy                           0.81      1755\n",
      "   macro avg       0.52      0.52      0.52      1755\n",
      "weighted avg       0.81      0.81      0.81      1755\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "score = baseline_model(texts,max_label,sender_num,Round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "def baseline_model(texts,labels,sender_num,Round):\n",
    "    texts = [str (item) for item in texts]\n",
    "    x_train = tfidf_vectorizer.fit_transform(texts).toarray()\n",
    "#     x_test = tfidf_vectorizer.transform(x_test)\n",
    "    svd = TruncatedSVD(n_components=400).fit(x_train)\n",
    "    reduced = svd.transform(x_train)\n",
    "    total = reduced.tolist()\n",
    "    for item in range(len(total)):\n",
    "        total[item] = np.append(total[item], sender_num[item])\n",
    "    for item in range(len(total)):\n",
    "        total[item] = np.append(total[item], Round[item])\n",
    "        \n",
    "    total = np.array(total)\n",
    "    labels = np.array(labels)        \n",
    "        \n",
    "    \n",
    "    Models = ['Bernoulli NB','Svm (linear)','Logistic Regression',\n",
    "              'Random Forest','kNN','Decision Tree']\n",
    "    function = [BernoulliNB(),svm.SVC(kernel=\"linear\"),LogisticRegression(),\n",
    "              RandomForestClassifier(),KNeighborsClassifier(),DecisionTreeClassifier()]\n",
    "    perform_f1 = []\n",
    "    perform_acc = []\n",
    "    perform_recall = []\n",
    "    perform_precision = []\n",
    "    \n",
    "    for i in tqdm(range(len(function))):\n",
    "        model = function[i]\n",
    "        performance = cross_val_score(model, total, labels, cv=10, scoring='accuracy')\n",
    "        performance1 = cross_val_score(model, total, labels, cv=10, scoring='f1_weighted')\n",
    "        performance2 = cross_val_score(model, total, labels, cv=10, scoring='recall')\n",
    "        performance3 = cross_val_score(model, total, labels, cv=10, scoring='precision')\n",
    "        \n",
    "        func = str(function[i])\n",
    "        print(\"==== \", func[0:func.index('(')], \" ====\")\n",
    "        perform_acc.append(performance.mean())\n",
    "        perform_f1.append(performance1.mean())\n",
    "        perform_recall.append(performance2.mean())\n",
    "        perform_precision.append(performance3.mean())\n",
    "\n",
    "#         model.fit(x_train, y_train)\n",
    "#         model.score(x_test, y_test)\n",
    "#         e = y_test\n",
    "#         p = model.predict(x_test)\n",
    "#         print(metrics.classification_report(e,p))\n",
    "#         perform_f1.append(metrics.f1_score(e,p,average='macro'))\n",
    "#         perform_acc.append(metrics.accuracy_score(e,p))\n",
    "        \n",
    "    result_f1_table = pd.DataFrame({\"Models\":Models,\"f1-scores\":perform_f1,\"accuracy\":perform_acc\n",
    "                                   ,\"recall\":perform_recall,\"precision\":perform_precision})\n",
    "#     result_acc_table = pd.DataFrame({\"Models\":Models,\"Result acc scores\":perform_acc})\n",
    "    return result_f1_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "score1 = baseline_model(texts,labels,sender_num,Round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
